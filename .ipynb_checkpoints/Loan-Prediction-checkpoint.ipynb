{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#data page https://www.kaggle.com/altruistdelhite04/loan-prediction-problem-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrap \n",
    "import sys \n",
    "import os\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def display_scores(model, x, y, metric='accuracy'):\n",
    "    scores = cross_val_score(model, x, y, scoring=metric, cv=3)\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard_deviation: \", scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Path to your own, test data doesn't have loan_status, might be on kaggle somewhere\n",
    "train_set = pd.read_csv('/media/tim/Primary Storage/Data/Loan Prediction/loan-prediction-problem-dataset/train_set.csv')\n",
    "test_set = pd.read_csv('/media/tim/Primary Storage/Data/Loan Prediction/loan-prediction-problem-dataset/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()\n",
    "# train_set = train_set.set_index(['Loan_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              614\n",
       "Gender               601\n",
       "Married              611\n",
       "Dependents           599\n",
       "Education            614\n",
       "Self_Employed        582\n",
       "ApplicantIncome      614\n",
       "CoapplicantIncome    614\n",
       "LoanAmount           592\n",
       "Loan_Amount_Term     600\n",
       "Credit_History       564\n",
       "Property_Area        614\n",
       "Loan_Status          614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.count() #pretty small, fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      "Loan_ID              614 non-null object\n",
      "Gender               601 non-null object\n",
      "Married              611 non-null object\n",
      "Dependents           599 non-null object\n",
      "Education            614 non-null object\n",
      "Self_Employed        582 non-null object\n",
      "ApplicantIncome      614 non-null int64\n",
      "CoapplicantIncome    614 non-null float64\n",
      "LoanAmount           592 non-null float64\n",
      "Loan_Amount_Term     600 non-null float64\n",
      "Credit_History       564 non-null float64\n",
      "Property_Area        614 non-null object\n",
      "Loan_Status          614 non-null object\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Remove Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i'm going to try and split these values down the road\n",
    "train_set['Gender'] = train_set['Gender'].fillna('Male') # default with male current\n",
    "train_set['Married'] = train_set['Married'].fillna('No') #\n",
    "train_set['Self_Employed'] = train_set['Self_Employed'].fillna('No')\n",
    "train_set['Dependents'] = train_set['Dependents'].fillna('0')\n",
    "train_set['Credit_History'] = train_set['Credit_History'].fillna(0.)\n",
    "\n",
    "\n",
    "#better practice for filling null values of all columns\n",
    "# cat_data = cat_data.apply(lambda x:x.fillna(x.value_counts().inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7f4f40f4c908>, Y    422\n",
       " N    192\n",
       " Name: Loan_Status, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#overall approval of loan statuts\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(train_set['Loan_Status']), train_set['Loan_Status'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x='Property_Area', hue='Loan_Status',  data=train_set);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f4f407d2be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 737.28x230.4 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#comparing credit history to loan approval \n",
    "loan_appr = sns.FacetGrid(train_set, col='Loan_Status', size=3.2, aspect=1.6)\n",
    "loan_appr.map(sns.countplot, 'Credit_History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>3833.5</td>\n",
       "      <td>268.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>3812.5</td>\n",
       "      <td>1239.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "Loan_Status                                                                     \n",
       "N                     3833.5              268.0       129.0             360.0   \n",
       "Y                     3812.5             1239.5       126.0             360.0   \n",
       "\n",
       "             Credit_History  \n",
       "Loan_Status                  \n",
       "N                       1.0  \n",
       "Y                       1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('Loan_Status').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, validation_set = train_test_split(train_set, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
    "x_valid = validation_set.drop(['Loan_Status', 'Loan_ID'], axis=1)\n",
    "\n",
    "y_train = train_set['Loan_Status'].copy()\n",
    "y_valid = validation_set['Loan_Status'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical: Loan_ID, Dependents, Gender, Self_Employed, Education, Married, Property_Area, Loan_Status\n",
    "\n",
    "Numerical:  Credit history, ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_attrbs = list(X_train.drop(['Gender', \n",
    "                                        'Married',\n",
    "                                        'Education',\n",
    "                                        'Self_Employed',\n",
    "                                        'Property_Area',\n",
    "                                        'Dependents',\n",
    "                                        \n",
    "                                            ], \n",
    "                                         axis=1))\n",
    "\n",
    "categorical_attrbs = list(X_train.drop([\n",
    "                                         'ApplicantIncome',\n",
    "                                         'CoapplicantIncome',\n",
    "                                         'LoanAmount',\n",
    "                                         'Loan_Amount_Term',\n",
    "                                        'Credit_History',\n",
    "                                         ], \n",
    "                                         axis=1), )\n",
    "\n",
    "\n",
    "# better method\n",
    "# categorical_attrbs = []\n",
    "# numerical_attrbs = []\n",
    "\n",
    "# for i,c in enumerate(train_set.dtypes):\n",
    "#     if c == object:\n",
    "#         categorical_attrbs.append(train_set.iloc[:, i])\n",
    "#     else :\n",
    "#         numerical_attrbs.append(train_set.iloc[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ApplicantIncome',\n",
       "  'CoapplicantIncome',\n",
       "  'LoanAmount',\n",
       "  'Loan_Amount_Term',\n",
       "  'Credit_History'],\n",
       " ['Gender',\n",
       "  'Married',\n",
       "  'Dependents',\n",
       "  'Education',\n",
       "  'Self_Employed',\n",
       "  'Property_Area'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(numerical_attrbs), list(categorical_attrbs),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: impute null values of categorical, if not one hot for those categories could use average?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), #cannot be mean or median (maybe make my own)\n",
    "    ('one_hot', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"numerical_pipeline\", numerical_pipeline, numerical_attrbs),\n",
    "    (\"categorical_pipeline\", categorical_pipeline, categorical_attrbs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = full_pipeline.fit_transform(X_train)\n",
    "x_valid = full_pipeline.fit_transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_valid = pd.DataFrame(y_valid)\n",
    "\n",
    "some_data = x_valid[:5]\n",
    "some_labels = y_valid[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the y_train \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_valid = encoder.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(x_train, y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 1., 0., 1.]),     Loan_Status\n",
       " 350           Y\n",
       " 377           Y\n",
       " 163           Y\n",
       " 609           Y\n",
       " 132           Y)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.predict(some_data), some_labels  #80% right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69047619, 0.75609756, 0.625     ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sgd_clf, x_valid, y_valid, cv=3, scoring='accuracy') #aprox 72-77% acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "logistic_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76190476, 0.7804878 , 0.75      ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(logistic_reg, x_valid, y_valid, cv=3) #84-85% better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1., 1.]),     Loan_Status\n",
       " 350           Y\n",
       " 377           Y\n",
       " 163           Y\n",
       " 609           Y\n",
       " 132           Y)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_reg.predict(some_data), some_labels #100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest-Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78571429, 0.82926829, 0.7       ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, x_valid, y_valid, cv=3) #77-84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_clf = SVC(random_state=42)\n",
    "svc_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76190476, 0.82926829, 0.75      ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc_clf, x_valid, y_valid, cv=3) #84 to 88%, might be overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_clf = DecisionTreeClassifier(random_state=42, max_depth=1)\n",
    "decision_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_clf.get_depth()  #overfitting, set max_depth to 1 or 2, slightly better w/ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76190476, 0.80487805, 0.75      ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(decision_clf, x_valid, y_valid, cv=3) #84-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data into a neural network\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "# TensorFlow 2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "bs_opt = keras.optimizers\n",
    "bs_act = keras.activations\n",
    "#could mess around with losses and metrics?\n",
    "\n",
    "input_shape= x_train[-1:]\n",
    "\n",
    "parameters_distributions = {\n",
    "    \"n_hidden\": [0, 1, 2, 3, 4],\n",
    "    \"n_neurons\":np.arange(1, 200),\n",
    "    \"learning_rate\": reciprocal(1e-4, 9e-2),\n",
    "    'optimizer':[  bs_opt.SGD(), bs_opt.RMSprop(), bs_opt.Adagrad(),\n",
    "                bs_opt.Nadam(), bs_opt.Ftrl(), bs_opt.Adadelta(),\n",
    "                bs_opt.Adam(), bs_opt.Adamax()],\n",
    "    'input_shape': input_shape, #streamline this\n",
    "    'activation': [ bs_act.elu, bs_act.exponential, bs_act.hard_sigmoid,\n",
    "                  bs_act.linear, bs_act.relu, bs_act.selu, bs_act.sigmoid,\n",
    "                  bs_act.tanh],\n",
    "    'drop_out_rate': np.arange(0.0, 1.0, step=0.1),\n",
    "    'exit_layer_act': [bs_act.linear, bs_act.exponential, bs_act.relu, bs_act.softmax],\n",
    "    'loss_fn': ['mse', 'mae']\n",
    "}\n",
    "#should save a new model each time it is ran\n",
    "# checkpoint_save = datetime.now().strftime('%Y%m%d_%H%M%S') # to implement \n",
    "checkpoint = keras.callbacks.ModelCheckpoint('best_classifier.hdf5', monitor='loss', \n",
    "                                            save_best_only= True, mode='auto',\n",
    "                                            save_freq=1)\n",
    "early_stop = keras.callbacks.EarlyStopping(patience=10, monitor='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=None, \n",
    "                drop_out_rate=.5, optimizer=None, activation=None,\n",
    "               exit_layer_act='linear', loss_fn='mse'):\n",
    "    #should make a call parms for kernel_initializer\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    #input layer\n",
    "#     model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    #hidden layers\n",
    "    for layer in range(n_hidden):   \n",
    "        model.add(keras.layers.Dense(n_neurons, activation=activation, kernel_initializer='lecun_normal'))\n",
    "        model.add(keras.layers.Dropout(rate=drop_out_rate))\n",
    "    #output layer, maybe make different possible activations for output layer\n",
    "    model.add(keras.layers.Dense(1, activation=exit_layer_act))\n",
    "    #optimizer \n",
    "    optimizer = keras.optimizers.RMSprop()\n",
    "    #compile, #could use multiple losses too\n",
    "    model.compile(loss= loss_fn, optimizer=optimizer, metrics=['mean_squared_error', 'accuracy'], )\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_regressor = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_iterations = number of parameter settings that are sampled\n",
    "#cv = cross folds of the data\n",
    "rand_search_cv = RandomizedSearchCV(keras_regressor, parameters_distributions, n_iter=10, \n",
    "                                   cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 1s 2ms/sample - loss: 0.6522 - mean_squared_error: 0.5744 - accuracy: 0.4190\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 138us/sample - loss: 0.5104 - mean_squared_error: 0.3926 - accuracy: 0.5627\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 478us/sample - loss: 0.4845 - mean_squared_error: 0.3473 - accuracy: 0.5841\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 336us/sample - loss: 0.4892 - mean_squared_error: 0.3709 - accuracy: 0.6239\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 85us/sample - loss: 0.5109 - mean_squared_error: 0.3922 - accuracy: 0.5749\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.5048 - mean_squared_error: 0.3851 - accuracy: 0.5596\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 82us/sample - loss: 0.4726 - mean_squared_error: 0.3490 - accuracy: 0.6361\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.4878 - mean_squared_error: 0.3761 - accuracy: 0.6269\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 77us/sample - loss: 0.4591 - mean_squared_error: 0.3326 - accuracy: 0.6147\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.4677 - mean_squared_error: 0.3329 - accuracy: 0.6177\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.4847 - mean_squared_error: 0.3586 - accuracy: 0.5933\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 164us/sample - loss: 0.4515 - mean_squared_error: 0.3238 - accuracy: 0.6300\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.4535 - mean_squared_error: 0.3247 - accuracy: 0.6208\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 137us/sample - loss: 0.4445 - mean_squared_error: 0.3096 - accuracy: 0.6544\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.4563 - mean_squared_error: 0.3264 - accuracy: 0.6300\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.4305 - mean_squared_error: 0.3128 - accuracy: 0.6606\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 86us/sample - loss: 0.4528 - mean_squared_error: 0.3410 - accuracy: 0.6239\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 104us/sample - loss: 0.4306 - mean_squared_error: 0.3017 - accuracy: 0.6575\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 100us/sample - loss: 0.4065 - mean_squared_error: 0.2694 - accuracy: 0.6636\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 91us/sample - loss: 0.4263 - mean_squared_error: 0.2870 - accuracy: 0.6697\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 209us/sample - loss: 0.4129 - mean_squared_error: 0.2786 - accuracy: 0.6606\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.4270 - mean_squared_error: 0.3055 - accuracy: 0.6483\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.4064 - mean_squared_error: 0.2689 - accuracy: 0.6881\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 90us/sample - loss: 0.4141 - mean_squared_error: 0.2899 - accuracy: 0.6606\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 80us/sample - loss: 0.4035 - mean_squared_error: 0.2841 - accuracy: 0.6728\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 86us/sample - loss: 0.4152 - mean_squared_error: 0.2929 - accuracy: 0.6606\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 83us/sample - loss: 0.3970 - mean_squared_error: 0.2615 - accuracy: 0.6789\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 96us/sample - loss: 0.4140 - mean_squared_error: 0.2800 - accuracy: 0.6697\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 89us/sample - loss: 0.4100 - mean_squared_error: 0.2995 - accuracy: 0.6728\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 99us/sample - loss: 0.3801 - mean_squared_error: 0.2586 - accuracy: 0.6881\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 93us/sample - loss: 0.3899 - mean_squared_error: 0.2582 - accuracy: 0.6911\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 123us/sample - loss: 0.3720 - mean_squared_error: 0.2530 - accuracy: 0.6942\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 90us/sample - loss: 0.3869 - mean_squared_error: 0.2634 - accuracy: 0.7034\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 97us/sample - loss: 0.3925 - mean_squared_error: 0.2782 - accuracy: 0.6758\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.4087 - mean_squared_error: 0.2881 - accuracy: 0.6820\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 95us/sample - loss: 0.3911 - mean_squared_error: 0.2729 - accuracy: 0.6942\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 146us/sample - loss: 0.3916 - mean_squared_error: 0.2746 - accuracy: 0.6881\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3886 - mean_squared_error: 0.2705 - accuracy: 0.6972\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.3779 - mean_squared_error: 0.2575 - accuracy: 0.6789\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3845 - mean_squared_error: 0.2641 - accuracy: 0.7003\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3658 - mean_squared_error: 0.2501 - accuracy: 0.7064\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3905 - mean_squared_error: 0.2689 - accuracy: 0.6972\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3931 - mean_squared_error: 0.2727 - accuracy: 0.6850\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3890 - mean_squared_error: 0.2684 - accuracy: 0.6942\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.3714 - mean_squared_error: 0.2643 - accuracy: 0.7003\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3789 - mean_squared_error: 0.2665 - accuracy: 0.6972\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3750 - mean_squared_error: 0.2717 - accuracy: 0.7156\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3829 - mean_squared_error: 0.2699 - accuracy: 0.7034\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3881 - mean_squared_error: 0.2804 - accuracy: 0.6972\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.3628 - mean_squared_error: 0.2464 - accuracy: 0.6881\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3787 - mean_squared_error: 0.2793 - accuracy: 0.7064\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3692 - mean_squared_error: 0.2590 - accuracy: 0.7003\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3717 - mean_squared_error: 0.2621 - accuracy: 0.7003\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.3722 - mean_squared_error: 0.2599 - accuracy: 0.7003\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.3837 - mean_squared_error: 0.2876 - accuracy: 0.7034\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 120us/sample - loss: 0.3685 - mean_squared_error: 0.2614 - accuracy: 0.7064\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3756 - mean_squared_error: 0.2707 - accuracy: 0.7064\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3655 - mean_squared_error: 0.2587 - accuracy: 0.6972\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 75us/sample - loss: 0.3726 - mean_squared_error: 0.2797 - accuracy: 0.7064\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 80us/sample - loss: 0.3674 - mean_squared_error: 0.2559 - accuracy: 0.7003\n",
      "164/164 [==============================] - 0s 761us/sample - loss: 0.3618 - mean_squared_error: 0.2630 - accuracy: 0.6768\n",
      "[CV]  activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   3.0s\n",
      "[CV] activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.8263 - mean_squared_error: 1.0054 - accuracy: 0.3731\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.6654 - mean_squared_error: 0.6692 - accuracy: 0.4618\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.5896 - mean_squared_error: 0.5339 - accuracy: 0.5291\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.5542 - mean_squared_error: 0.4762 - accuracy: 0.5535\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.6441 - mean_squared_error: 0.6035 - accuracy: 0.4587\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.5459 - mean_squared_error: 0.4620 - accuracy: 0.5596\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.5399 - mean_squared_error: 0.4372 - accuracy: 0.5566\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.4925 - mean_squared_error: 0.3809 - accuracy: 0.5872\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.5357 - mean_squared_error: 0.4271 - accuracy: 0.5291\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.4905 - mean_squared_error: 0.3825 - accuracy: 0.6177\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.4799 - mean_squared_error: 0.3585 - accuracy: 0.6147\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.5174 - mean_squared_error: 0.4180 - accuracy: 0.5933\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.5007 - mean_squared_error: 0.3862 - accuracy: 0.5872\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4775 - mean_squared_error: 0.3459 - accuracy: 0.5994\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.4784 - mean_squared_error: 0.3509 - accuracy: 0.5902\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.4687 - mean_squared_error: 0.3385 - accuracy: 0.6391\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4710 - mean_squared_error: 0.3522 - accuracy: 0.5963\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.4785 - mean_squared_error: 0.3438 - accuracy: 0.5963\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4609 - mean_squared_error: 0.3365 - accuracy: 0.5963\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.4536 - mean_squared_error: 0.3310 - accuracy: 0.6422\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.4648 - mean_squared_error: 0.3371 - accuracy: 0.5902\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.4541 - mean_squared_error: 0.3256 - accuracy: 0.5963\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.4601 - mean_squared_error: 0.3285 - accuracy: 0.6330\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.4499 - mean_squared_error: 0.3007 - accuracy: 0.6024\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.4595 - mean_squared_error: 0.3196 - accuracy: 0.5994\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.4384 - mean_squared_error: 0.3181 - accuracy: 0.6544\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.4379 - mean_squared_error: 0.2908 - accuracy: 0.6086\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4478 - mean_squared_error: 0.3263 - accuracy: 0.6177\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4129 - mean_squared_error: 0.2787 - accuracy: 0.6391\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.4419 - mean_squared_error: 0.3081 - accuracy: 0.6086\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4252 - mean_squared_error: 0.2965 - accuracy: 0.6453\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.4281 - mean_squared_error: 0.3163 - accuracy: 0.6483\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.4423 - mean_squared_error: 0.3177 - accuracy: 0.6575\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.4326 - mean_squared_error: 0.2934 - accuracy: 0.6606\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.4185 - mean_squared_error: 0.2974 - accuracy: 0.6728\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.4142 - mean_squared_error: 0.2808 - accuracy: 0.6483\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.4115 - mean_squared_error: 0.2853 - accuracy: 0.6789\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.4147 - mean_squared_error: 0.2870 - accuracy: 0.6453\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 90us/sample - loss: 0.4073 - mean_squared_error: 0.2888 - accuracy: 0.6636\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 125us/sample - loss: 0.4101 - mean_squared_error: 0.2872 - accuracy: 0.6544\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 109us/sample - loss: 0.4089 - mean_squared_error: 0.2800 - accuracy: 0.6606\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 102us/sample - loss: 0.3899 - mean_squared_error: 0.2607 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 95us/sample - loss: 0.4131 - mean_squared_error: 0.2699 - accuracy: 0.6361\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 93us/sample - loss: 0.4089 - mean_squared_error: 0.2915 - accuracy: 0.6697\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 192us/sample - loss: 0.3977 - mean_squared_error: 0.2648 - accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.3994 - mean_squared_error: 0.2779 - accuracy: 0.6789\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 75us/sample - loss: 0.4045 - mean_squared_error: 0.2814 - accuracy: 0.6697\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 77us/sample - loss: 0.4065 - mean_squared_error: 0.2945 - accuracy: 0.6820\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.4009 - mean_squared_error: 0.2723 - accuracy: 0.6881\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3928 - mean_squared_error: 0.2718 - accuracy: 0.6758\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 78us/sample - loss: 0.3946 - mean_squared_error: 0.2773 - accuracy: 0.6758\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.4200 - mean_squared_error: 0.2931 - accuracy: 0.6544\n",
      "164/164 [==============================] - 0s 402us/sample - loss: 0.3453 - mean_squared_error: 0.2259 - accuracy: 0.7134\n",
      "[CV]  activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   1.7s\n",
      "[CV] activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 1ms/sample - loss: 0.5611 - mean_squared_error: 0.4625 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.5323 - mean_squared_error: 0.4188 - accuracy: 0.5518\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.5249 - mean_squared_error: 0.4269 - accuracy: 0.5610\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.5375 - mean_squared_error: 0.4369 - accuracy: 0.5640\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.5275 - mean_squared_error: 0.4411 - accuracy: 0.5884\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.4950 - mean_squared_error: 0.3906 - accuracy: 0.6128\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.5152 - mean_squared_error: 0.4024 - accuracy: 0.5762\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.4812 - mean_squared_error: 0.3679 - accuracy: 0.6067\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.4928 - mean_squared_error: 0.3782 - accuracy: 0.6250\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.4808 - mean_squared_error: 0.3435 - accuracy: 0.5884\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 0.4909 - mean_squared_error: 0.3713 - accuracy: 0.6098\n",
      "Epoch 12/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.4656 - mean_squared_error: 0.3311 - accuracy: 0.6098\n",
      "Epoch 13/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4881 - mean_squared_error: 0.3664 - accuracy: 0.5854\n",
      "Epoch 14/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 0.4597 - mean_squared_error: 0.3133 - accuracy: 0.6037\n",
      "Epoch 15/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.4580 - mean_squared_error: 0.3138 - accuracy: 0.6280\n",
      "Epoch 16/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.4394 - mean_squared_error: 0.3069 - accuracy: 0.6189\n",
      "Epoch 17/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.4382 - mean_squared_error: 0.3087 - accuracy: 0.6220\n",
      "Epoch 18/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.4354 - mean_squared_error: 0.3050 - accuracy: 0.6341\n",
      "Epoch 19/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.4497 - mean_squared_error: 0.3283 - accuracy: 0.6463\n",
      "Epoch 20/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 0.4471 - mean_squared_error: 0.3130 - accuracy: 0.6524\n",
      "Epoch 21/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.4347 - mean_squared_error: 0.2926 - accuracy: 0.6494\n",
      "Epoch 22/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: 0.4250 - mean_squared_error: 0.3011 - accuracy: 0.6555\n",
      "Epoch 23/100\n",
      "328/328 [==============================] - 0s 91us/sample - loss: 0.4228 - mean_squared_error: 0.2768 - accuracy: 0.6585\n",
      "Epoch 24/100\n",
      "328/328 [==============================] - 0s 88us/sample - loss: 0.4417 - mean_squared_error: 0.3123 - accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "328/328 [==============================] - 0s 101us/sample - loss: 0.4202 - mean_squared_error: 0.2966 - accuracy: 0.6738\n",
      "Epoch 26/100\n",
      "328/328 [==============================] - 0s 85us/sample - loss: 0.4131 - mean_squared_error: 0.2725 - accuracy: 0.6524\n",
      "Epoch 27/100\n",
      "328/328 [==============================] - 0s 79us/sample - loss: 0.4281 - mean_squared_error: 0.3032 - accuracy: 0.6341\n",
      "Epoch 28/100\n",
      "328/328 [==============================] - 0s 95us/sample - loss: 0.4068 - mean_squared_error: 0.2807 - accuracy: 0.6860\n",
      "Epoch 29/100\n",
      "328/328 [==============================] - 0s 85us/sample - loss: 0.4086 - mean_squared_error: 0.2858 - accuracy: 0.6707\n",
      "Epoch 30/100\n",
      "328/328 [==============================] - 0s 93us/sample - loss: 0.4205 - mean_squared_error: 0.2923 - accuracy: 0.6555\n",
      "Epoch 31/100\n",
      "328/328 [==============================] - 0s 100us/sample - loss: 0.4041 - mean_squared_error: 0.2659 - accuracy: 0.6677\n",
      "Epoch 32/100\n",
      "328/328 [==============================] - 0s 84us/sample - loss: 0.3937 - mean_squared_error: 0.2694 - accuracy: 0.6707\n",
      "Epoch 33/100\n",
      "328/328 [==============================] - 0s 84us/sample - loss: 0.4026 - mean_squared_error: 0.2795 - accuracy: 0.6768\n",
      "Epoch 34/100\n",
      "328/328 [==============================] - 0s 88us/sample - loss: 0.3897 - mean_squared_error: 0.2592 - accuracy: 0.6768\n",
      "Epoch 35/100\n",
      "328/328 [==============================] - 0s 70us/sample - loss: 0.4077 - mean_squared_error: 0.2706 - accuracy: 0.6799\n",
      "Epoch 36/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.4022 - mean_squared_error: 0.2745 - accuracy: 0.6677\n",
      "Epoch 37/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.4000 - mean_squared_error: 0.2700 - accuracy: 0.6616\n",
      "Epoch 38/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3997 - mean_squared_error: 0.2894 - accuracy: 0.6707\n",
      "Epoch 39/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.4100 - mean_squared_error: 0.2940 - accuracy: 0.6524\n",
      "Epoch 40/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.4079 - mean_squared_error: 0.2783 - accuracy: 0.6829\n",
      "Epoch 41/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3965 - mean_squared_error: 0.2849 - accuracy: 0.6799\n",
      "Epoch 42/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.3975 - mean_squared_error: 0.2951 - accuracy: 0.6921\n",
      "Epoch 43/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3861 - mean_squared_error: 0.2650 - accuracy: 0.6707\n",
      "Epoch 44/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3891 - mean_squared_error: 0.2774 - accuracy: 0.6799\n",
      "Epoch 45/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3923 - mean_squared_error: 0.2783 - accuracy: 0.6646\n",
      "Epoch 46/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 0.3667 - mean_squared_error: 0.2580 - accuracy: 0.6890\n",
      "Epoch 47/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4002 - mean_squared_error: 0.2777 - accuracy: 0.6707\n",
      "Epoch 48/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.3883 - mean_squared_error: 0.2800 - accuracy: 0.6738\n",
      "Epoch 49/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.3936 - mean_squared_error: 0.2759 - accuracy: 0.6799\n",
      "Epoch 50/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3893 - mean_squared_error: 0.2796 - accuracy: 0.6860\n",
      "Epoch 51/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3834 - mean_squared_error: 0.2803 - accuracy: 0.6799\n",
      "Epoch 52/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.3854 - mean_squared_error: 0.2776 - accuracy: 0.6829\n",
      "Epoch 53/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.3752 - mean_squared_error: 0.2663 - accuracy: 0.6890\n",
      "Epoch 54/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.3797 - mean_squared_error: 0.2817 - accuracy: 0.6982\n",
      "Epoch 55/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.3641 - mean_squared_error: 0.2492 - accuracy: 0.6951\n",
      "Epoch 56/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 0.3713 - mean_squared_error: 0.2643 - accuracy: 0.6768\n",
      "Epoch 57/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 0.3757 - mean_squared_error: 0.2669 - accuracy: 0.6951\n",
      "Epoch 58/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.3848 - mean_squared_error: 0.2803 - accuracy: 0.6921\n",
      "Epoch 59/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 0.3685 - mean_squared_error: 0.2622 - accuracy: 0.6921\n",
      "Epoch 60/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3835 - mean_squared_error: 0.2611 - accuracy: 0.6951\n",
      "Epoch 61/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 0.3736 - mean_squared_error: 0.2640 - accuracy: 0.6890\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 42us/sample - loss: 0.3864 - mean_squared_error: 0.2856 - accuracy: 0.6921\n",
      "Epoch 63/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.3736 - mean_squared_error: 0.2784 - accuracy: 0.6951\n",
      "Epoch 64/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.3873 - mean_squared_error: 0.2713 - accuracy: 0.6951\n",
      "Epoch 65/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.3763 - mean_squared_error: 0.2635 - accuracy: 0.6921\n",
      "163/163 [==============================] - 0s 421us/sample - loss: 0.3415 - mean_squared_error: 0.2482 - accuracy: 0.6994\n",
      "[CV]  activation=<function sigmoid at 0x7f4eed7e5d08>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00034826582042536035, loss_fn=mae, n_hidden=4, n_neurons=21, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   1.9s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2966\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 73us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "164/164 [==============================] - 0s 408us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3232\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978>, total=   0.8s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "164/164 [==============================] - 0s 398us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2866\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978>, total=   0.8s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 82us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 74us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 71us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "163/163 [==============================] - 0s 399us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3006\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.2, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014845440072092295, loss_fn=mae, n_hidden=4, n_neurons=100, optimizer=<tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978>, total=   0.8s\n",
      "[CV] activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.6064 - mean_squared_error: 0.5779 - accuracy: 0.4434\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 71us/sample - loss: 0.5379 - mean_squared_error: 0.4416 - accuracy: 0.5046\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.5027 - mean_squared_error: 0.3463 - accuracy: 0.5505\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.4494 - mean_squared_error: 0.3041 - accuracy: 0.6728\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.4600 - mean_squared_error: 0.3024 - accuracy: 0.6575\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.4498 - mean_squared_error: 0.3150 - accuracy: 0.6972\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4605 - mean_squared_error: 0.3231 - accuracy: 0.6544\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.4260 - mean_squared_error: 0.2588 - accuracy: 0.6972\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.4295 - mean_squared_error: 0.2678 - accuracy: 0.6881\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.4572 - mean_squared_error: 0.3283 - accuracy: 0.6728\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.4160 - mean_squared_error: 0.2695 - accuracy: 0.7248\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4074 - mean_squared_error: 0.2449 - accuracy: 0.7064\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 90us/sample - loss: 0.4231 - mean_squared_error: 0.2729 - accuracy: 0.6850\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 73us/sample - loss: 0.4225 - mean_squared_error: 0.2918 - accuracy: 0.7064\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 81us/sample - loss: 0.4260 - mean_squared_error: 0.2627 - accuracy: 0.7034\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.4213 - mean_squared_error: 0.2497 - accuracy: 0.7034\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.4033 - mean_squared_error: 0.2413 - accuracy: 0.7034\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.3982 - mean_squared_error: 0.2371 - accuracy: 0.7370\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 76us/sample - loss: 0.3858 - mean_squared_error: 0.2257 - accuracy: 0.7401\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.3718 - mean_squared_error: 0.2176 - accuracy: 0.7339\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3973 - mean_squared_error: 0.2391 - accuracy: 0.7431\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3856 - mean_squared_error: 0.2465 - accuracy: 0.7492\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.3833 - mean_squared_error: 0.2135 - accuracy: 0.7401\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.3888 - mean_squared_error: 0.2293 - accuracy: 0.7492\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3867 - mean_squared_error: 0.2274 - accuracy: 0.7523\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.3813 - mean_squared_error: 0.2336 - accuracy: 0.7584\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3682 - mean_squared_error: 0.2118 - accuracy: 0.7492\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.3854 - mean_squared_error: 0.2366 - accuracy: 0.7339\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.3758 - mean_squared_error: 0.2185 - accuracy: 0.7431\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3737 - mean_squared_error: 0.2074 - accuracy: 0.7248\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3759 - mean_squared_error: 0.2219 - accuracy: 0.7462\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3936 - mean_squared_error: 0.2540 - accuracy: 0.7431\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3834 - mean_squared_error: 0.2409 - accuracy: 0.7339\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3477 - mean_squared_error: 0.1974 - accuracy: 0.7645\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.3542 - mean_squared_error: 0.1999 - accuracy: 0.7615\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.3630 - mean_squared_error: 0.2036 - accuracy: 0.7370\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3668 - mean_squared_error: 0.2097 - accuracy: 0.7278\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.3570 - mean_squared_error: 0.2008 - accuracy: 0.7676\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3482 - mean_squared_error: 0.1888 - accuracy: 0.7645\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 72us/sample - loss: 0.3671 - mean_squared_error: 0.2276 - accuracy: 0.7554\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 76us/sample - loss: 0.3588 - mean_squared_error: 0.2103 - accuracy: 0.7645\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.3556 - mean_squared_error: 0.2046 - accuracy: 0.7615\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 91us/sample - loss: 0.3451 - mean_squared_error: 0.1995 - accuracy: 0.7615\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.3550 - mean_squared_error: 0.2137 - accuracy: 0.7615\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.3419 - mean_squared_error: 0.2064 - accuracy: 0.7676\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3539 - mean_squared_error: 0.2052 - accuracy: 0.7554\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3480 - mean_squared_error: 0.2136 - accuracy: 0.7554\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3509 - mean_squared_error: 0.2161 - accuracy: 0.7645\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.3349 - mean_squared_error: 0.1929 - accuracy: 0.7615\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.3295 - mean_squared_error: 0.1864 - accuracy: 0.7798\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3514 - mean_squared_error: 0.2122 - accuracy: 0.7584\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3461 - mean_squared_error: 0.1968 - accuracy: 0.7584\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.3465 - mean_squared_error: 0.2150 - accuracy: 0.7768\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3320 - mean_squared_error: 0.2060 - accuracy: 0.7615\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.3321 - mean_squared_error: 0.1922 - accuracy: 0.7829\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3275 - mean_squared_error: 0.1959 - accuracy: 0.7584\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3400 - mean_squared_error: 0.2027 - accuracy: 0.7584\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3373 - mean_squared_error: 0.1846 - accuracy: 0.7615\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 77us/sample - loss: 0.3163 - mean_squared_error: 0.1918 - accuracy: 0.7645\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 75us/sample - loss: 0.3203 - mean_squared_error: 0.1857 - accuracy: 0.7706\n",
      "Epoch 61/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3110 - mean_squared_error: 0.1812 - accuracy: 0.7615\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 71us/sample - loss: 0.3171 - mean_squared_error: 0.1992 - accuracy: 0.7615\n",
      "Epoch 63/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.3213 - mean_squared_error: 0.1853 - accuracy: 0.7706\n",
      "Epoch 64/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3185 - mean_squared_error: 0.1825 - accuracy: 0.7798\n",
      "Epoch 65/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.3207 - mean_squared_error: 0.1941 - accuracy: 0.7768\n",
      "Epoch 66/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3121 - mean_squared_error: 0.1882 - accuracy: 0.7645\n",
      "Epoch 67/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3168 - mean_squared_error: 0.1973 - accuracy: 0.7768\n",
      "Epoch 68/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.3123 - mean_squared_error: 0.1884 - accuracy: 0.7737\n",
      "Epoch 69/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.3166 - mean_squared_error: 0.1892 - accuracy: 0.7737\n",
      "Epoch 70/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3099 - mean_squared_error: 0.1977 - accuracy: 0.7768\n",
      "Epoch 71/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3166 - mean_squared_error: 0.1967 - accuracy: 0.7706\n",
      "Epoch 72/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3043 - mean_squared_error: 0.1808 - accuracy: 0.7737\n",
      "Epoch 73/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.3103 - mean_squared_error: 0.1918 - accuracy: 0.7768\n",
      "Epoch 74/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3054 - mean_squared_error: 0.1903 - accuracy: 0.7706\n",
      "Epoch 75/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.3074 - mean_squared_error: 0.1856 - accuracy: 0.7615\n",
      "Epoch 76/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3047 - mean_squared_error: 0.1878 - accuracy: 0.7737\n",
      "Epoch 77/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3083 - mean_squared_error: 0.1952 - accuracy: 0.7676\n",
      "Epoch 78/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.3122 - mean_squared_error: 0.1961 - accuracy: 0.7737\n",
      "Epoch 79/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3022 - mean_squared_error: 0.1863 - accuracy: 0.7737\n",
      "Epoch 80/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.2975 - mean_squared_error: 0.1788 - accuracy: 0.7615\n",
      "Epoch 81/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.2951 - mean_squared_error: 0.1854 - accuracy: 0.7737\n",
      "Epoch 82/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.2978 - mean_squared_error: 0.1861 - accuracy: 0.7706\n",
      "Epoch 83/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3028 - mean_squared_error: 0.1860 - accuracy: 0.7829\n",
      "Epoch 84/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.2952 - mean_squared_error: 0.1823 - accuracy: 0.7768\n",
      "Epoch 85/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.2925 - mean_squared_error: 0.1807 - accuracy: 0.7798\n",
      "Epoch 86/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.2869 - mean_squared_error: 0.1772 - accuracy: 0.7920\n",
      "Epoch 87/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.2915 - mean_squared_error: 0.1902 - accuracy: 0.7768\n",
      "Epoch 88/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.2989 - mean_squared_error: 0.1860 - accuracy: 0.7706\n",
      "Epoch 89/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.2865 - mean_squared_error: 0.1728 - accuracy: 0.7706\n",
      "Epoch 90/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.2945 - mean_squared_error: 0.1848 - accuracy: 0.7737\n",
      "Epoch 91/100\n",
      "327/327 [==============================] - 0s 148us/sample - loss: 0.2934 - mean_squared_error: 0.1864 - accuracy: 0.7584\n",
      "Epoch 92/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.2896 - mean_squared_error: 0.1825 - accuracy: 0.7768\n",
      "Epoch 93/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.2932 - mean_squared_error: 0.1766 - accuracy: 0.7798\n",
      "Epoch 94/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.2963 - mean_squared_error: 0.1810 - accuracy: 0.7737\n",
      "Epoch 95/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.2891 - mean_squared_error: 0.1806 - accuracy: 0.7768\n",
      "Epoch 96/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.2939 - mean_squared_error: 0.1846 - accuracy: 0.7768\n",
      "Epoch 97/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.2819 - mean_squared_error: 0.1748 - accuracy: 0.7768\n",
      "Epoch 98/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.2849 - mean_squared_error: 0.1876 - accuracy: 0.7859\n",
      "Epoch 99/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.2861 - mean_squared_error: 0.1670 - accuracy: 0.7768\n",
      "Epoch 100/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.2845 - mean_squared_error: 0.1672 - accuracy: 0.7768\n",
      "164/164 [==============================] - 0s 372us/sample - loss: 0.3337 - mean_squared_error: 0.2278 - accuracy: 0.7500\n",
      "[CV]  activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   2.8s\n",
      "[CV] activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.6214 - mean_squared_error: 0.7675 - accuracy: 0.4771\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.4843 - mean_squared_error: 0.3630 - accuracy: 0.6239\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4633 - mean_squared_error: 0.3228 - accuracy: 0.5994\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 85us/sample - loss: 0.4525 - mean_squared_error: 0.3012 - accuracy: 0.6269\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.4747 - mean_squared_error: 0.3357 - accuracy: 0.6208\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3992 - mean_squared_error: 0.2627 - accuracy: 0.7278\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.4296 - mean_squared_error: 0.2933 - accuracy: 0.6728\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.4507 - mean_squared_error: 0.3214 - accuracy: 0.6391\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.4035 - mean_squared_error: 0.2465 - accuracy: 0.7034\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.4125 - mean_squared_error: 0.2591 - accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3845 - mean_squared_error: 0.2373 - accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.4187 - mean_squared_error: 0.2732 - accuracy: 0.6789\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3771 - mean_squared_error: 0.2325 - accuracy: 0.7554\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 59us/sample - loss: 0.3970 - mean_squared_error: 0.2347 - accuracy: 0.7125\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.4091 - mean_squared_error: 0.2733 - accuracy: 0.7187\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3733 - mean_squared_error: 0.2257 - accuracy: 0.7064\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 72us/sample - loss: 0.3797 - mean_squared_error: 0.2229 - accuracy: 0.7278\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3949 - mean_squared_error: 0.2246 - accuracy: 0.7064\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3802 - mean_squared_error: 0.2192 - accuracy: 0.7125\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.3732 - mean_squared_error: 0.2201 - accuracy: 0.7615\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.3804 - mean_squared_error: 0.2483 - accuracy: 0.7370\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3900 - mean_squared_error: 0.2324 - accuracy: 0.7156\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3845 - mean_squared_error: 0.2306 - accuracy: 0.7370\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3628 - mean_squared_error: 0.2290 - accuracy: 0.7829\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3615 - mean_squared_error: 0.2244 - accuracy: 0.7645\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.3674 - mean_squared_error: 0.2204 - accuracy: 0.7645\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3622 - mean_squared_error: 0.2174 - accuracy: 0.8012\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.3556 - mean_squared_error: 0.2046 - accuracy: 0.7523\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3770 - mean_squared_error: 0.2363 - accuracy: 0.7523\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 86us/sample - loss: 0.3751 - mean_squared_error: 0.2322 - accuracy: 0.7309\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.3632 - mean_squared_error: 0.2166 - accuracy: 0.7676\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3634 - mean_squared_error: 0.2181 - accuracy: 0.7920\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3599 - mean_squared_error: 0.2053 - accuracy: 0.7584\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3407 - mean_squared_error: 0.2051 - accuracy: 0.7859\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 0.3271 - mean_squared_error: 0.1952 - accuracy: 0.7920\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 79us/sample - loss: 0.3533 - mean_squared_error: 0.2070 - accuracy: 0.7462\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 72us/sample - loss: 0.3382 - mean_squared_error: 0.2025 - accuracy: 0.7920\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 132us/sample - loss: 0.3344 - mean_squared_error: 0.2095 - accuracy: 0.7737\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3495 - mean_squared_error: 0.1984 - accuracy: 0.7951\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 91us/sample - loss: 0.3298 - mean_squared_error: 0.2088 - accuracy: 0.7951\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3439 - mean_squared_error: 0.2000 - accuracy: 0.7737\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.3200 - mean_squared_error: 0.1884 - accuracy: 0.7951\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.3452 - mean_squared_error: 0.2008 - accuracy: 0.7920\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.3377 - mean_squared_error: 0.2001 - accuracy: 0.7737\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.3292 - mean_squared_error: 0.1955 - accuracy: 0.7890\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3316 - mean_squared_error: 0.2223 - accuracy: 0.7768\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.3209 - mean_squared_error: 0.1927 - accuracy: 0.7920\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.3170 - mean_squared_error: 0.1847 - accuracy: 0.7859\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.3331 - mean_squared_error: 0.1910 - accuracy: 0.7890\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3203 - mean_squared_error: 0.1753 - accuracy: 0.7829\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3125 - mean_squared_error: 0.1828 - accuracy: 0.7920\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 72us/sample - loss: 0.3118 - mean_squared_error: 0.1917 - accuracy: 0.7920\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3299 - mean_squared_error: 0.2064 - accuracy: 0.7951\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3125 - mean_squared_error: 0.1875 - accuracy: 0.7920\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 71us/sample - loss: 0.3113 - mean_squared_error: 0.1911 - accuracy: 0.7798\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3081 - mean_squared_error: 0.1889 - accuracy: 0.7920\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3049 - mean_squared_error: 0.1941 - accuracy: 0.7829\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.3099 - mean_squared_error: 0.1771 - accuracy: 0.7920\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.3013 - mean_squared_error: 0.1893 - accuracy: 0.7859\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.3089 - mean_squared_error: 0.1981 - accuracy: 0.7890\n",
      "Epoch 61/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.2956 - mean_squared_error: 0.1906 - accuracy: 0.7890\n",
      "Epoch 62/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.2965 - mean_squared_error: 0.1823 - accuracy: 0.7920\n",
      "Epoch 63/100\n",
      "327/327 [==============================] - 0s 81us/sample - loss: 0.2968 - mean_squared_error: 0.1790 - accuracy: 0.7859\n",
      "Epoch 64/100\n",
      "327/327 [==============================] - 0s 337us/sample - loss: 0.3064 - mean_squared_error: 0.1955 - accuracy: 0.7859\n",
      "Epoch 65/100\n",
      "327/327 [==============================] - 0s 103us/sample - loss: 0.3037 - mean_squared_error: 0.1931 - accuracy: 0.7859\n",
      "Epoch 66/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.3032 - mean_squared_error: 0.1897 - accuracy: 0.7890\n",
      "Epoch 67/100\n",
      "327/327 [==============================] - 0s 245us/sample - loss: 0.2921 - mean_squared_error: 0.1971 - accuracy: 0.7920\n",
      "Epoch 68/100\n",
      "327/327 [==============================] - 0s 84us/sample - loss: 0.2894 - mean_squared_error: 0.1996 - accuracy: 0.7920\n",
      "Epoch 69/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.2842 - mean_squared_error: 0.1789 - accuracy: 0.7890\n",
      "Epoch 70/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 0.2803 - mean_squared_error: 0.1881 - accuracy: 0.7890\n",
      "Epoch 71/100\n",
      "327/327 [==============================] - 0s 80us/sample - loss: 0.2818 - mean_squared_error: 0.1753 - accuracy: 0.7798\n",
      "Epoch 72/100\n",
      "327/327 [==============================] - 0s 68us/sample - loss: 0.2845 - mean_squared_error: 0.1892 - accuracy: 0.7890\n",
      "Epoch 73/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 0.2892 - mean_squared_error: 0.1827 - accuracy: 0.7890\n",
      "Epoch 74/100\n",
      "327/327 [==============================] - 0s 85us/sample - loss: 0.2840 - mean_squared_error: 0.1765 - accuracy: 0.7982\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 68us/sample - loss: 0.2735 - mean_squared_error: 0.1683 - accuracy: 0.7951\n",
      "Epoch 76/100\n",
      "327/327 [==============================] - 0s 86us/sample - loss: 0.2848 - mean_squared_error: 0.1873 - accuracy: 0.7982\n",
      "Epoch 77/100\n",
      "327/327 [==============================] - 0s 97us/sample - loss: 0.2898 - mean_squared_error: 0.1876 - accuracy: 0.7951\n",
      "Epoch 78/100\n",
      "327/327 [==============================] - 0s 78us/sample - loss: 0.2850 - mean_squared_error: 0.1768 - accuracy: 0.7890\n",
      "Epoch 79/100\n",
      "327/327 [==============================] - 0s 84us/sample - loss: 0.2724 - mean_squared_error: 0.1721 - accuracy: 0.7920\n",
      "Epoch 80/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 0.2804 - mean_squared_error: 0.1831 - accuracy: 0.7920\n",
      "Epoch 81/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 0.2880 - mean_squared_error: 0.1854 - accuracy: 0.7890\n",
      "Epoch 82/100\n",
      "327/327 [==============================] - 0s 71us/sample - loss: 0.2817 - mean_squared_error: 0.1846 - accuracy: 0.8012\n",
      "Epoch 83/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.2788 - mean_squared_error: 0.1795 - accuracy: 0.8012\n",
      "Epoch 84/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.2749 - mean_squared_error: 0.1762 - accuracy: 0.7829\n",
      "Epoch 85/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 0.2811 - mean_squared_error: 0.1810 - accuracy: 0.7920\n",
      "Epoch 86/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.2742 - mean_squared_error: 0.1777 - accuracy: 0.7890\n",
      "Epoch 87/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 0.2742 - mean_squared_error: 0.1904 - accuracy: 0.7951\n",
      "Epoch 88/100\n",
      "327/327 [==============================] - 0s 73us/sample - loss: 0.2729 - mean_squared_error: 0.1773 - accuracy: 0.7920\n",
      "Epoch 89/100\n",
      "327/327 [==============================] - 0s 81us/sample - loss: 0.2814 - mean_squared_error: 0.1930 - accuracy: 0.7920\n",
      "164/164 [==============================] - 0s 358us/sample - loss: 0.3509 - mean_squared_error: 0.2351 - accuracy: 0.7256\n",
      "[CV]  activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   2.6s\n",
      "[CV] activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 1ms/sample - loss: 0.5888 - mean_squared_error: 0.5316 - accuracy: 0.5061\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 0.4885 - mean_squared_error: 0.3474 - accuracy: 0.6128\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 64us/sample - loss: 0.4756 - mean_squared_error: 0.3310 - accuracy: 0.6037\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.5204 - mean_squared_error: 0.3903 - accuracy: 0.5335\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.4427 - mean_squared_error: 0.3138 - accuracy: 0.6616\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.4450 - mean_squared_error: 0.3153 - accuracy: 0.6951\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.4210 - mean_squared_error: 0.2629 - accuracy: 0.6799\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: 0.4236 - mean_squared_error: 0.2972 - accuracy: 0.7043\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 0.4469 - mean_squared_error: 0.3161 - accuracy: 0.6646\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.4160 - mean_squared_error: 0.2491 - accuracy: 0.6951\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.4194 - mean_squared_error: 0.2682 - accuracy: 0.7012\n",
      "Epoch 12/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.4093 - mean_squared_error: 0.2758 - accuracy: 0.7012\n",
      "Epoch 13/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.4046 - mean_squared_error: 0.2464 - accuracy: 0.7165\n",
      "Epoch 14/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.4008 - mean_squared_error: 0.2463 - accuracy: 0.7165\n",
      "Epoch 15/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.4135 - mean_squared_error: 0.2547 - accuracy: 0.6890\n",
      "Epoch 16/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.4356 - mean_squared_error: 0.3348 - accuracy: 0.7043\n",
      "Epoch 17/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.3904 - mean_squared_error: 0.2412 - accuracy: 0.7561\n",
      "Epoch 18/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 0.3721 - mean_squared_error: 0.2211 - accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 0.3882 - mean_squared_error: 0.2450 - accuracy: 0.7256\n",
      "Epoch 20/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3698 - mean_squared_error: 0.2111 - accuracy: 0.7287\n",
      "Epoch 21/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3997 - mean_squared_error: 0.2519 - accuracy: 0.7348\n",
      "Epoch 22/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 0.3783 - mean_squared_error: 0.2485 - accuracy: 0.7439\n",
      "Epoch 23/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3904 - mean_squared_error: 0.2463 - accuracy: 0.7439\n",
      "Epoch 24/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 0.3644 - mean_squared_error: 0.2174 - accuracy: 0.7652\n",
      "Epoch 25/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.3840 - mean_squared_error: 0.2449 - accuracy: 0.7470\n",
      "Epoch 26/100\n",
      "328/328 [==============================] - 0s 76us/sample - loss: 0.3694 - mean_squared_error: 0.2380 - accuracy: 0.7713\n",
      "Epoch 27/100\n",
      "328/328 [==============================] - 0s 76us/sample - loss: 0.3756 - mean_squared_error: 0.2299 - accuracy: 0.7470\n",
      "Epoch 28/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 0.3691 - mean_squared_error: 0.2231 - accuracy: 0.7622\n",
      "Epoch 29/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: 0.3663 - mean_squared_error: 0.2309 - accuracy: 0.7591\n",
      "Epoch 30/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.3641 - mean_squared_error: 0.2334 - accuracy: 0.7622\n",
      "Epoch 31/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.3776 - mean_squared_error: 0.2307 - accuracy: 0.7409\n",
      "Epoch 32/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: 0.3632 - mean_squared_error: 0.2267 - accuracy: 0.7530\n",
      "Epoch 33/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3633 - mean_squared_error: 0.2320 - accuracy: 0.7591\n",
      "Epoch 34/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3547 - mean_squared_error: 0.2117 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3601 - mean_squared_error: 0.2088 - accuracy: 0.7530\n",
      "Epoch 36/100\n",
      "328/328 [==============================] - 0s 78us/sample - loss: 0.3595 - mean_squared_error: 0.2577 - accuracy: 0.7683\n",
      "Epoch 37/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: 0.3389 - mean_squared_error: 0.2132 - accuracy: 0.7774\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 56us/sample - loss: 0.3341 - mean_squared_error: 0.2117 - accuracy: 0.7652\n",
      "Epoch 39/100\n",
      "328/328 [==============================] - 0s 85us/sample - loss: 0.3617 - mean_squared_error: 0.2251 - accuracy: 0.7470\n",
      "Epoch 40/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3479 - mean_squared_error: 0.2190 - accuracy: 0.7652\n",
      "Epoch 41/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.3375 - mean_squared_error: 0.2052 - accuracy: 0.7683\n",
      "Epoch 42/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3382 - mean_squared_error: 0.2132 - accuracy: 0.7713\n",
      "Epoch 43/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 0.3385 - mean_squared_error: 0.2164 - accuracy: 0.7683\n",
      "Epoch 44/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3320 - mean_squared_error: 0.2105 - accuracy: 0.7744\n",
      "Epoch 45/100\n",
      "328/328 [==============================] - 0s 76us/sample - loss: 0.3430 - mean_squared_error: 0.2175 - accuracy: 0.7713\n",
      "Epoch 46/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3294 - mean_squared_error: 0.2181 - accuracy: 0.7652\n",
      "Epoch 47/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.3491 - mean_squared_error: 0.2387 - accuracy: 0.7683\n",
      "Epoch 48/100\n",
      "328/328 [==============================] - 0s 76us/sample - loss: 0.3323 - mean_squared_error: 0.2092 - accuracy: 0.7744\n",
      "Epoch 49/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 0.3335 - mean_squared_error: 0.2133 - accuracy: 0.7561\n",
      "Epoch 50/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.3223 - mean_squared_error: 0.2046 - accuracy: 0.7683\n",
      "Epoch 51/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.3250 - mean_squared_error: 0.1991 - accuracy: 0.7683\n",
      "Epoch 52/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.3251 - mean_squared_error: 0.2177 - accuracy: 0.7744\n",
      "Epoch 53/100\n",
      "328/328 [==============================] - 0s 82us/sample - loss: 0.3258 - mean_squared_error: 0.2165 - accuracy: 0.7744\n",
      "Epoch 54/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3139 - mean_squared_error: 0.2049 - accuracy: 0.7744\n",
      "Epoch 55/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.3123 - mean_squared_error: 0.1955 - accuracy: 0.7744\n",
      "Epoch 56/100\n",
      "328/328 [==============================] - 0s 87us/sample - loss: 0.3199 - mean_squared_error: 0.2035 - accuracy: 0.7683\n",
      "Epoch 57/100\n",
      "328/328 [==============================] - 0s 50us/sample - loss: 0.3115 - mean_squared_error: 0.2000 - accuracy: 0.7805\n",
      "Epoch 58/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3212 - mean_squared_error: 0.2131 - accuracy: 0.7744\n",
      "Epoch 59/100\n",
      "328/328 [==============================] - 0s 94us/sample - loss: 0.3101 - mean_squared_error: 0.2082 - accuracy: 0.7774\n",
      "Epoch 60/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3129 - mean_squared_error: 0.2020 - accuracy: 0.7652\n",
      "Epoch 61/100\n",
      "328/328 [==============================] - 0s 70us/sample - loss: 0.3126 - mean_squared_error: 0.2017 - accuracy: 0.7683\n",
      "Epoch 62/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.3058 - mean_squared_error: 0.1979 - accuracy: 0.7713\n",
      "Epoch 63/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.3091 - mean_squared_error: 0.1950 - accuracy: 0.7683\n",
      "Epoch 64/100\n",
      "328/328 [==============================] - 0s 85us/sample - loss: 0.2985 - mean_squared_error: 0.1976 - accuracy: 0.7713\n",
      "Epoch 65/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3079 - mean_squared_error: 0.2027 - accuracy: 0.7744\n",
      "Epoch 66/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3052 - mean_squared_error: 0.2042 - accuracy: 0.7744\n",
      "Epoch 67/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 0.3036 - mean_squared_error: 0.2014 - accuracy: 0.7713\n",
      "Epoch 68/100\n",
      "328/328 [==============================] - 0s 72us/sample - loss: 0.2901 - mean_squared_error: 0.1936 - accuracy: 0.7744\n",
      "Epoch 69/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.2975 - mean_squared_error: 0.1891 - accuracy: 0.7713\n",
      "Epoch 70/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3039 - mean_squared_error: 0.2042 - accuracy: 0.7713\n",
      "Epoch 71/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3072 - mean_squared_error: 0.2076 - accuracy: 0.7713\n",
      "Epoch 72/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.2993 - mean_squared_error: 0.1987 - accuracy: 0.7744\n",
      "Epoch 73/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 0.2898 - mean_squared_error: 0.1915 - accuracy: 0.7713\n",
      "Epoch 74/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 0.2989 - mean_squared_error: 0.2059 - accuracy: 0.7774\n",
      "Epoch 75/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.2885 - mean_squared_error: 0.1848 - accuracy: 0.7774\n",
      "Epoch 76/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 0.2960 - mean_squared_error: 0.2056 - accuracy: 0.7713\n",
      "Epoch 77/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.2955 - mean_squared_error: 0.2056 - accuracy: 0.7713\n",
      "Epoch 78/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.2928 - mean_squared_error: 0.1966 - accuracy: 0.7744\n",
      "Epoch 79/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.2824 - mean_squared_error: 0.1938 - accuracy: 0.7774\n",
      "Epoch 80/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 0.2860 - mean_squared_error: 0.1894 - accuracy: 0.7805\n",
      "Epoch 81/100\n",
      "328/328 [==============================] - 0s 72us/sample - loss: 0.2947 - mean_squared_error: 0.2095 - accuracy: 0.7744\n",
      "Epoch 82/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.2846 - mean_squared_error: 0.1944 - accuracy: 0.7713\n",
      "Epoch 83/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.2810 - mean_squared_error: 0.1880 - accuracy: 0.7774\n",
      "Epoch 84/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.2971 - mean_squared_error: 0.2052 - accuracy: 0.7683\n",
      "Epoch 85/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.2859 - mean_squared_error: 0.1941 - accuracy: 0.7744\n",
      "Epoch 86/100\n",
      "328/328 [==============================] - 0s 70us/sample - loss: 0.2842 - mean_squared_error: 0.1940 - accuracy: 0.7713\n",
      "Epoch 87/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.2876 - mean_squared_error: 0.1980 - accuracy: 0.7744\n",
      "Epoch 88/100\n",
      "328/328 [==============================] - 0s 75us/sample - loss: 0.2811 - mean_squared_error: 0.1919 - accuracy: 0.7652\n",
      "Epoch 89/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 0.2777 - mean_squared_error: 0.1911 - accuracy: 0.7744\n",
      "Epoch 90/100\n",
      "328/328 [==============================] - 0s 78us/sample - loss: 0.2832 - mean_squared_error: 0.1995 - accuracy: 0.7713\n",
      "Epoch 91/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.2886 - mean_squared_error: 0.1989 - accuracy: 0.7744\n",
      "Epoch 92/100\n",
      "328/328 [==============================] - 0s 80us/sample - loss: 0.2890 - mean_squared_error: 0.1933 - accuracy: 0.7744\n",
      "Epoch 93/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.2909 - mean_squared_error: 0.1927 - accuracy: 0.7713\n",
      "Epoch 94/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 0.2814 - mean_squared_error: 0.1890 - accuracy: 0.7713\n",
      "Epoch 95/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.2876 - mean_squared_error: 0.1978 - accuracy: 0.7774\n",
      "Epoch 96/100\n",
      "328/328 [==============================] - 0s 65us/sample - loss: 0.2916 - mean_squared_error: 0.2018 - accuracy: 0.7713\n",
      "Epoch 97/100\n",
      "328/328 [==============================] - 0s 73us/sample - loss: 0.2795 - mean_squared_error: 0.1964 - accuracy: 0.7744\n",
      "Epoch 98/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.2782 - mean_squared_error: 0.1875 - accuracy: 0.7744\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 69us/sample - loss: 0.2784 - mean_squared_error: 0.1950 - accuracy: 0.7774\n",
      "163/163 [==============================] - 0s 360us/sample - loss: 0.2630 - mean_squared_error: 0.2136 - accuracy: 0.7669\n",
      "[CV]  activation=<function tanh at 0x7f4eed7e5c80>, drop_out_rate=0.2, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00014677547170664106, loss_fn=mae, n_hidden=3, n_neurons=158, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   2.7s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "164/164 [==============================] - 0s 389us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3232\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898>, total=   0.7s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3119\n",
      "164/164 [==============================] - 0s 415us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2866\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898>, total=   0.7s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 69us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 89us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 87us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 64us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 94us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "163/163 [==============================] - 0s 1ms/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0523 13:41:40.594832 139979530426176 nn_ops.py:4372] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0523 13:41:40.611646 139979530426176 nn_ops.py:4372] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0523 13:41:40.669860 139979530426176 nn_ops.py:4372] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0523 13:41:40.680911 139979530426176 nn_ops.py:4372] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.4, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00079214624399565, loss_fn=mae, n_hidden=4, n_neurons=89, optimizer=<tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f4eec396898>, total=   0.9s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0523 13:41:40.791788 139979530426176 nn_ops.py:4372] Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 994us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 140us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 72us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "164/164 [==============================] - 0s 371us/sample - loss: 0.3232 - mean_squared_error: 0.3232 - accuracy: 0.6768\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 927us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 77us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "164/164 [==============================] - 0s 416us/sample - loss: 0.2866 - mean_squared_error: 0.2866 - accuracy: 0.7134\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 968us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 63us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 50us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "163/163 [==============================] - 0s 384us/sample - loss: 0.3006 - mean_squared_error: 0.3006 - accuracy: 0.6994\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.9, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0007295686093122072, loss_fn=mae, n_hidden=2, n_neurons=108, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 426.8557 - mean_squared_error: 426.8557 - accuracy: 0.4893\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 242.0786 - mean_squared_error: 242.0786 - accuracy: 0.4679\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 179.5825 - mean_squared_error: 179.5825 - accuracy: 0.4954\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 347.2732 - mean_squared_error: 347.2732 - accuracy: 0.4740\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 205.3896 - mean_squared_error: 205.3896 - accuracy: 0.4709\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 136.4744 - mean_squared_error: 136.4744 - accuracy: 0.5199\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 168.0938 - mean_squared_error: 168.0938 - accuracy: 0.4740\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 200.5533 - mean_squared_error: 200.5533 - accuracy: 0.4832\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 235.1616 - mean_squared_error: 235.1616 - accuracy: 0.4801\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 146.6400 - mean_squared_error: 146.6400 - accuracy: 0.5168\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 163.6619 - mean_squared_error: 163.6619 - accuracy: 0.4465\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 217.3164 - mean_squared_error: 217.3164 - accuracy: 0.4373\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 86.1067 - mean_squared_error: 86.1067 - accuracy: 0.4465\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 92.4657 - mean_squared_error: 92.4657 - accuracy: 0.4526\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 96.4655 - mean_squared_error: 96.4655 - accuracy: 0.4281\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 75.3263 - mean_squared_error: 75.3263 - accuracy: 0.4709\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 87.1469 - mean_squared_error: 87.1469 - accuracy: 0.4526\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 80.3574 - mean_squared_error: 80.3574 - accuracy: 0.4220\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 57.8004 - mean_squared_error: 57.8004 - accuracy: 0.4251\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 72.3444 - mean_squared_error: 72.3444 - accuracy: 0.4190\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 160.4049 - mean_squared_error: 160.4049 - accuracy: 0.4312\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 50.1401 - mean_squared_error: 50.1401 - accuracy: 0.4190\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 72.7151 - mean_squared_error: 72.7151 - accuracy: 0.4465\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 55.5234 - mean_squared_error: 55.5233 - accuracy: 0.4067\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 61.4388 - mean_squared_error: 61.4388 - accuracy: 0.4343\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 89.9521 - mean_squared_error: 89.9521 - accuracy: 0.4373\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 74.1614 - mean_squared_error: 74.1614 - accuracy: 0.4281\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 37.6803 - mean_squared_error: 37.6803 - accuracy: 0.4220\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 39.6421 - mean_squared_error: 39.6421 - accuracy: 0.3853\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 25.5892 - mean_squared_error: 25.5892 - accuracy: 0.4098\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 16.7570 - mean_squared_error: 16.7570 - accuracy: 0.4312\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 19.2538 - mean_squared_error: 19.2538 - accuracy: 0.4526\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 17.2945 - mean_squared_error: 17.2945 - accuracy: 0.3853\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 20.1545 - mean_squared_error: 20.1545 - accuracy: 0.4128\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 41.7311 - mean_squared_error: 41.7311 - accuracy: 0.4037\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 17.3295 - mean_squared_error: 17.3295 - accuracy: 0.3761\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 16.8138 - mean_squared_error: 16.8138 - accuracy: 0.3761\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 23.8583 - mean_squared_error: 23.8583 - accuracy: 0.3578\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 15.5335 - mean_squared_error: 15.5335 - accuracy: 0.3914\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 27.2671 - mean_squared_error: 27.2671 - accuracy: 0.4281\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 18.2712 - mean_squared_error: 18.2712 - accuracy: 0.3761\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 14.5591 - mean_squared_error: 14.5591 - accuracy: 0.3670\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 13.1897 - mean_squared_error: 13.1897 - accuracy: 0.3456\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 79us/sample - loss: 9.9783 - mean_squared_error: 9.9783 - accuracy: 0.3486\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 10.0724 - mean_squared_error: 10.0724 - accuracy: 0.3364\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 9.6845 - mean_squared_error: 9.6845 - accuracy: 0.3456\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 16.4199 - mean_squared_error: 16.4199 - accuracy: 0.3364\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 69us/sample - loss: 11.3781 - mean_squared_error: 11.3781 - accuracy: 0.3456\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 14.4938 - mean_squared_error: 14.4938 - accuracy: 0.3456\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 7.8615 - mean_squared_error: 7.8615 - accuracy: 0.3578\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 4.5524 - mean_squared_error: 4.5524 - accuracy: 0.3670\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 17.9879 - mean_squared_error: 17.9879 - accuracy: 0.3394\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 3.5231 - mean_squared_error: 3.5231 - accuracy: 0.3731\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 5.9319 - mean_squared_error: 5.9319 - accuracy: 0.3272\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 5.4326 - mean_squared_error: 5.4326 - accuracy: 0.3761\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 9.4610 - mean_squared_error: 9.4610 - accuracy: 0.3456\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 3.7600 - mean_squared_error: 3.7600 - accuracy: 0.3211\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 3.9583 - mean_squared_error: 3.9583 - accuracy: 0.3456\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 4.0384 - mean_squared_error: 4.0384 - accuracy: 0.3456\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 2.2308 - mean_squared_error: 2.2308 - accuracy: 0.3394\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 54us/sample - loss: 4.1008 - mean_squared_error: 4.1008 - accuracy: 0.3150\n",
      "Epoch 62/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 4.1025 - mean_squared_error: 4.1025 - accuracy: 0.3517\n",
      "Epoch 63/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 2.4671 - mean_squared_error: 2.4671 - accuracy: 0.3303\n",
      "Epoch 64/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 5.4089 - mean_squared_error: 5.4089 - accuracy: 0.3242\n",
      "Epoch 65/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 2.0590 - mean_squared_error: 2.0590 - accuracy: 0.3456\n",
      "Epoch 66/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 2.0385 - mean_squared_error: 2.0385 - accuracy: 0.3425\n",
      "Epoch 67/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 2.8524 - mean_squared_error: 2.8524 - accuracy: 0.3242\n",
      "Epoch 68/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 2.8742 - mean_squared_error: 2.8742 - accuracy: 0.3486\n",
      "Epoch 69/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 6.8280 - mean_squared_error: 6.8280 - accuracy: 0.3180\n",
      "Epoch 70/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 2.6849 - mean_squared_error: 2.6849 - accuracy: 0.3150\n",
      "Epoch 71/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 2.5474 - mean_squared_error: 2.5474 - accuracy: 0.3303\n",
      "Epoch 72/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 4.4258 - mean_squared_error: 4.4258 - accuracy: 0.3058\n",
      "Epoch 73/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 1.1506 - mean_squared_error: 1.1506 - accuracy: 0.2875\n",
      "Epoch 74/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 3.8851 - mean_squared_error: 3.8851 - accuracy: 0.3486\n",
      "Epoch 75/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 1.4361 - mean_squared_error: 1.4361 - accuracy: 0.3272\n",
      "Epoch 76/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 2.0334 - mean_squared_error: 2.0334 - accuracy: 0.3119\n",
      "Epoch 77/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 1.2398 - mean_squared_error: 1.2398 - accuracy: 0.3119\n",
      "Epoch 78/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 1.6815 - mean_squared_error: 1.6815 - accuracy: 0.3028\n",
      "Epoch 79/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 2.1491 - mean_squared_error: 2.1491 - accuracy: 0.3272\n",
      "Epoch 80/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 2.8165 - mean_squared_error: 2.8165 - accuracy: 0.3028\n",
      "Epoch 81/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 2.9425 - mean_squared_error: 2.9425 - accuracy: 0.2997\n",
      "Epoch 82/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 1.5610 - mean_squared_error: 1.5610 - accuracy: 0.2936\n",
      "Epoch 83/100\n",
      "327/327 [==============================] - 0s 71us/sample - loss: 2.8878 - mean_squared_error: 2.8878 - accuracy: 0.2936\n",
      "164/164 [==============================] - 0s 360us/sample - loss: 0.6768 - mean_squared_error: 0.6768 - accuracy: 0.3232\n",
      "[CV]  activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   2.0s\n",
      "[CV] activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 588.7559 - mean_squared_error: 588.7558 - accuracy: 0.4832\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 263.6798 - mean_squared_error: 263.6798 - accuracy: 0.4281\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 189.5625 - mean_squared_error: 189.5625 - accuracy: 0.4526\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 237.2681 - mean_squared_error: 237.2681 - accuracy: 0.5168\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 193.2624 - mean_squared_error: 193.2624 - accuracy: 0.4373\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 163.5300 - mean_squared_error: 163.5300 - accuracy: 0.4404\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 104.1725 - mean_squared_error: 104.1725 - accuracy: 0.4648\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 175.4523 - mean_squared_error: 175.4523 - accuracy: 0.4679\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 224.6985 - mean_squared_error: 224.6985 - accuracy: 0.4343\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 138.1901 - mean_squared_error: 138.1901 - accuracy: 0.4648\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 116.8435 - mean_squared_error: 116.8435 - accuracy: 0.4648\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 69.0135 - mean_squared_error: 69.0135 - accuracy: 0.4495\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 91.8626 - mean_squared_error: 91.8626 - accuracy: 0.4006\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 48.0923 - mean_squared_error: 48.0923 - accuracy: 0.4220\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 100.9450 - mean_squared_error: 100.9450 - accuracy: 0.4709\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 60.0609 - mean_squared_error: 60.0609 - accuracy: 0.4495\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 59.4311 - mean_squared_error: 59.4311 - accuracy: 0.4679\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 98.2742 - mean_squared_error: 98.2742 - accuracy: 0.4159\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 165.0432 - mean_squared_error: 165.0432 - accuracy: 0.3853\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 110.0820 - mean_squared_error: 110.0820 - accuracy: 0.4404\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 33.4055 - mean_squared_error: 33.4055 - accuracy: 0.3700\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 33.9467 - mean_squared_error: 33.9467 - accuracy: 0.4557\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 77.6760 - mean_squared_error: 77.6760 - accuracy: 0.4220\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 34.5965 - mean_squared_error: 34.5965 - accuracy: 0.4128\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 60.0382 - mean_squared_error: 60.0382 - accuracy: 0.3792\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 41.9396 - mean_squared_error: 41.9396 - accuracy: 0.3945\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 71us/sample - loss: 21.7342 - mean_squared_error: 21.7342 - accuracy: 0.4098\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 27.4711 - mean_squared_error: 27.4711 - accuracy: 0.4037\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 54us/sample - loss: 25.0185 - mean_squared_error: 25.0185 - accuracy: 0.4128\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 32.7199 - mean_squared_error: 32.7199 - accuracy: 0.4067\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 87us/sample - loss: 20.9335 - mean_squared_error: 20.9335 - accuracy: 0.4037\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 15.0274 - mean_squared_error: 15.0274 - accuracy: 0.3456\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 42.5943 - mean_squared_error: 42.5943 - accuracy: 0.3609\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 14.9090 - mean_squared_error: 14.9090 - accuracy: 0.3517\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 23.6147 - mean_squared_error: 23.6147 - accuracy: 0.3884\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 17.2934 - mean_squared_error: 17.2934 - accuracy: 0.4006\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 7.4754 - mean_squared_error: 7.4754 - accuracy: 0.3700\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 12.4326 - mean_squared_error: 12.4326 - accuracy: 0.3486\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 21.3268 - mean_squared_error: 21.3268 - accuracy: 0.3853\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 24.6185 - mean_squared_error: 24.6185 - accuracy: 0.3700\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 17.6364 - mean_squared_error: 17.6364 - accuracy: 0.3547\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 9.7639 - mean_squared_error: 9.7639 - accuracy: 0.3486\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 12.1027 - mean_squared_error: 12.1027 - accuracy: 0.3731\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 24.0680 - mean_squared_error: 24.0680 - accuracy: 0.3639\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 5.6088 - mean_squared_error: 5.6088 - accuracy: 0.3853\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 28.9515 - mean_squared_error: 28.9515 - accuracy: 0.3853\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 6.8723 - mean_squared_error: 6.8723 - accuracy: 0.3670\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 5.4807 - mean_squared_error: 5.4807 - accuracy: 0.3486\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 7.5186 - mean_squared_error: 7.5186 - accuracy: 0.3792\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 4.6789 - mean_squared_error: 4.6789 - accuracy: 0.3028\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 74us/sample - loss: 3.7280 - mean_squared_error: 3.7280 - accuracy: 0.3547\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 7.1609 - mean_squared_error: 7.1609 - accuracy: 0.3578\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 11.4791 - mean_squared_error: 11.4791 - accuracy: 0.3272\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 2.7675 - mean_squared_error: 2.7675 - accuracy: 0.2997\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 4.7826 - mean_squared_error: 4.7826 - accuracy: 0.3761\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 11.8790 - mean_squared_error: 11.8790 - accuracy: 0.3242\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 2.7462 - mean_squared_error: 2.7462 - accuracy: 0.3211\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 7.5650 - mean_squared_error: 7.5650 - accuracy: 0.3639\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 3.8847 - mean_squared_error: 3.8847 - accuracy: 0.3486\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 2.1517 - mean_squared_error: 2.1517 - accuracy: 0.3211\n",
      "Epoch 61/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 17.9154 - mean_squared_error: 17.9154 - accuracy: 0.3303\n",
      "Epoch 62/100\n",
      "327/327 [==============================] - 0s 65us/sample - loss: 5.6067 - mean_squared_error: 5.6067 - accuracy: 0.3456\n",
      "Epoch 63/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 2.8258 - mean_squared_error: 2.8258 - accuracy: 0.3486\n",
      "Epoch 64/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 3.1515 - mean_squared_error: 3.1515 - accuracy: 0.3180\n",
      "Epoch 65/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 2.1458 - mean_squared_error: 2.1458 - accuracy: 0.3119\n",
      "Epoch 66/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 4.4725 - mean_squared_error: 4.4725 - accuracy: 0.3486\n",
      "Epoch 67/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 2.4488 - mean_squared_error: 2.4488 - accuracy: 0.3211\n",
      "Epoch 68/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 1.1887 - mean_squared_error: 1.1887 - accuracy: 0.3456\n",
      "Epoch 69/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 2.3843 - mean_squared_error: 2.3843 - accuracy: 0.3517\n",
      "Epoch 70/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 2.2690 - mean_squared_error: 2.2690 - accuracy: 0.3272\n",
      "Epoch 71/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 1.6249 - mean_squared_error: 1.6249 - accuracy: 0.3119\n",
      "Epoch 72/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 3.3138 - mean_squared_error: 3.3138 - accuracy: 0.3364\n",
      "Epoch 73/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 6.8398 - mean_squared_error: 6.8398 - accuracy: 0.3333\n",
      "Epoch 74/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 2.5720 - mean_squared_error: 2.5720 - accuracy: 0.3211\n",
      "Epoch 75/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 7.6270 - mean_squared_error: 7.6270 - accuracy: 0.3486\n",
      "Epoch 76/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 1.0517 - mean_squared_error: 1.0517 - accuracy: 0.3180\n",
      "Epoch 77/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 1.1103 - mean_squared_error: 1.1103 - accuracy: 0.3180\n",
      "Epoch 78/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 7.8778 - mean_squared_error: 7.8778 - accuracy: 0.3150\n",
      "Epoch 79/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 1.0341 - mean_squared_error: 1.0341 - accuracy: 0.3303\n",
      "Epoch 80/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 1.3824 - mean_squared_error: 1.3824 - accuracy: 0.3333\n",
      "Epoch 81/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 1.4909 - mean_squared_error: 1.4909 - accuracy: 0.3150\n",
      "Epoch 82/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 1.3759 - mean_squared_error: 1.3759 - accuracy: 0.3180\n",
      "Epoch 83/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 1.5620 - mean_squared_error: 1.5620 - accuracy: 0.3303\n",
      "Epoch 84/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.7723 - mean_squared_error: 0.7723 - accuracy: 0.3180\n",
      "Epoch 85/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 1.1501 - mean_squared_error: 1.1501 - accuracy: 0.3333\n",
      "Epoch 86/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.9821 - mean_squared_error: 0.9821 - accuracy: 0.3272\n",
      "Epoch 87/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 1.3233 - mean_squared_error: 1.3233 - accuracy: 0.3180\n",
      "Epoch 88/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.9656 - mean_squared_error: 0.9656 - accuracy: 0.3211\n",
      "Epoch 89/100\n",
      "327/327 [==============================] - 0s 64us/sample - loss: 2.0360 - mean_squared_error: 2.0360 - accuracy: 0.3119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 10.9913 - mean_squared_error: 10.9913 - accuracy: 0.3211\n",
      "Epoch 91/100\n",
      "327/327 [==============================] - 0s 80us/sample - loss: 1.6294 - mean_squared_error: 1.6294 - accuracy: 0.3211\n",
      "Epoch 92/100\n",
      "327/327 [==============================] - 0s 70us/sample - loss: 1.2735 - mean_squared_error: 1.2735 - accuracy: 0.3058\n",
      "Epoch 93/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 1.5902 - mean_squared_error: 1.5902 - accuracy: 0.3394\n",
      "Epoch 94/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 1.3380 - mean_squared_error: 1.3380 - accuracy: 0.3089\n",
      "164/164 [==============================] - 0s 391us/sample - loss: 0.7134 - mean_squared_error: 0.7134 - accuracy: 0.2866\n",
      "[CV]  activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   2.3s\n",
      "[CV] activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 1s 2ms/sample - loss: 255.9943 - mean_squared_error: 255.9943 - accuracy: 0.5091\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 216.7591 - mean_squared_error: 216.7591 - accuracy: 0.4878\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 220.5810 - mean_squared_error: 220.5810 - accuracy: 0.4451\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 67us/sample - loss: 163.6030 - mean_squared_error: 163.6030 - accuracy: 0.4756\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 151.5520 - mean_squared_error: 151.5520 - accuracy: 0.4299\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 148.1944 - mean_squared_error: 148.1944 - accuracy: 0.4787\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 141.1546 - mean_squared_error: 141.1546 - accuracy: 0.4482\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 140.9757 - mean_squared_error: 140.9757 - accuracy: 0.4299\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 186.4581 - mean_squared_error: 186.4581 - accuracy: 0.4360\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 73us/sample - loss: 79.3910 - mean_squared_error: 79.3910 - accuracy: 0.4390\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 72.3948 - mean_squared_error: 72.3948 - accuracy: 0.5091\n",
      "Epoch 12/100\n",
      "328/328 [==============================] - 0s 64us/sample - loss: 172.0655 - mean_squared_error: 172.0655 - accuracy: 0.4512\n",
      "Epoch 13/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 112.6162 - mean_squared_error: 112.6162 - accuracy: 0.4512\n",
      "Epoch 14/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 102.1834 - mean_squared_error: 102.1834 - accuracy: 0.4604\n",
      "Epoch 15/100\n",
      "328/328 [==============================] - 0s 64us/sample - loss: 61.8192 - mean_squared_error: 61.8192 - accuracy: 0.4268\n",
      "Epoch 16/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 49.5753 - mean_squared_error: 49.5753 - accuracy: 0.4604\n",
      "Epoch 17/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 63.6562 - mean_squared_error: 63.6562 - accuracy: 0.4543\n",
      "Epoch 18/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 114.6287 - mean_squared_error: 114.6287 - accuracy: 0.4238\n",
      "Epoch 19/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 66.8828 - mean_squared_error: 66.8828 - accuracy: 0.4055\n",
      "Epoch 20/100\n",
      "328/328 [==============================] - 0s 72us/sample - loss: 44.3202 - mean_squared_error: 44.3202 - accuracy: 0.4116\n",
      "Epoch 21/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 30.7227 - mean_squared_error: 30.7227 - accuracy: 0.4177\n",
      "Epoch 22/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 35.5026 - mean_squared_error: 35.5026 - accuracy: 0.3811\n",
      "Epoch 23/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 25.0525 - mean_squared_error: 25.0525 - accuracy: 0.3811\n",
      "Epoch 24/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 26.2562 - mean_squared_error: 26.2562 - accuracy: 0.4024\n",
      "Epoch 25/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 33.6980 - mean_squared_error: 33.6980 - accuracy: 0.4299\n",
      "Epoch 26/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 47.2436 - mean_squared_error: 47.2436 - accuracy: 0.4055\n",
      "Epoch 27/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 34.9306 - mean_squared_error: 34.9306 - accuracy: 0.4360\n",
      "Epoch 28/100\n",
      "328/328 [==============================] - 0s 50us/sample - loss: 19.4677 - mean_squared_error: 19.4677 - accuracy: 0.3720\n",
      "Epoch 29/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 42.7382 - mean_squared_error: 42.7382 - accuracy: 0.4055\n",
      "Epoch 30/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 17.5212 - mean_squared_error: 17.5212 - accuracy: 0.3354\n",
      "Epoch 31/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 51.8223 - mean_squared_error: 51.8223 - accuracy: 0.4177\n",
      "Epoch 32/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 26.6588 - mean_squared_error: 26.6588 - accuracy: 0.3994\n",
      "Epoch 33/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 23.0581 - mean_squared_error: 23.0581 - accuracy: 0.3567\n",
      "Epoch 34/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 20.9896 - mean_squared_error: 20.9896 - accuracy: 0.3598\n",
      "Epoch 35/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 27.8292 - mean_squared_error: 27.8292 - accuracy: 0.3872\n",
      "Epoch 36/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 17.7780 - mean_squared_error: 17.7780 - accuracy: 0.3872\n",
      "Epoch 37/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 36.4578 - mean_squared_error: 36.4578 - accuracy: 0.3201\n",
      "Epoch 38/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 14.9470 - mean_squared_error: 14.9470 - accuracy: 0.3811\n",
      "Epoch 39/100\n",
      "328/328 [==============================] - 0s 62us/sample - loss: 13.9783 - mean_squared_error: 13.9783 - accuracy: 0.3750\n",
      "Epoch 40/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 5.9281 - mean_squared_error: 5.9281 - accuracy: 0.3689\n",
      "Epoch 41/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 12.2005 - mean_squared_error: 12.2005 - accuracy: 0.3506\n",
      "Epoch 42/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 13.5284 - mean_squared_error: 13.5284 - accuracy: 0.3537\n",
      "Epoch 43/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 27.3205 - mean_squared_error: 27.3205 - accuracy: 0.3750\n",
      "Epoch 44/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 7.8080 - mean_squared_error: 7.8080 - accuracy: 0.3902\n",
      "Epoch 45/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 11.3506 - mean_squared_error: 11.3506 - accuracy: 0.3537\n",
      "Epoch 46/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 8.4411 - mean_squared_error: 8.4411 - accuracy: 0.3811\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 45us/sample - loss: 19.5066 - mean_squared_error: 19.5066 - accuracy: 0.3476\n",
      "Epoch 48/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 7.4027 - mean_squared_error: 7.4027 - accuracy: 0.3750\n",
      "Epoch 49/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 6.3217 - mean_squared_error: 6.3217 - accuracy: 0.3628\n",
      "Epoch 50/100\n",
      "328/328 [==============================] - 0s 68us/sample - loss: 6.3461 - mean_squared_error: 6.3461 - accuracy: 0.3506\n",
      "163/163 [==============================] - 0s 403us/sample - loss: 0.6994 - mean_squared_error: 0.6994 - accuracy: 0.3006\n",
      "[CV]  activation=<function linear at 0x7f4eed7e5ea0>, drop_out_rate=0.8, exit_layer_act=<function relu at 0x7f4eed7e5bf8>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.03471142996643913, loss_fn=mse, n_hidden=4, n_neurons=73, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   1.7s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 710us/sample - loss: 1.6573 - mean_squared_error: 7.0302 - accuracy: 0.5321\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 35us/sample - loss: 1.4746 - mean_squared_error: 4.9467 - accuracy: 0.5199\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 1.4907 - mean_squared_error: 5.3442 - accuracy: 0.4771\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 62us/sample - loss: 1.3025 - mean_squared_error: 4.6589 - accuracy: 0.4893\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 1.2533 - mean_squared_error: 2.9824 - accuracy: 0.4618\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 1.1216 - mean_squared_error: 3.0515 - accuracy: 0.5138\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 1.1111 - mean_squared_error: 2.7890 - accuracy: 0.5627\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.9585 - mean_squared_error: 2.1335 - accuracy: 0.5657\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.9693 - mean_squared_error: 1.7158 - accuracy: 0.5015\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.8481 - mean_squared_error: 1.2194 - accuracy: 0.5443\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.8772 - mean_squared_error: 1.7948 - accuracy: 0.5321\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.8120 - mean_squared_error: 1.3996 - accuracy: 0.5321\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 35us/sample - loss: 0.8019 - mean_squared_error: 1.3074 - accuracy: 0.5596\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.6809 - mean_squared_error: 0.8338 - accuracy: 0.5841\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.7123 - mean_squared_error: 0.8186 - accuracy: 0.5229\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.6342 - mean_squared_error: 0.7049 - accuracy: 0.5872\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.6283 - mean_squared_error: 0.7058 - accuracy: 0.5719\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.6545 - mean_squared_error: 0.8194 - accuracy: 0.5627\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.6245 - mean_squared_error: 0.7462 - accuracy: 0.5474\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.6169 - mean_squared_error: 0.6027 - accuracy: 0.5535\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.5088 - mean_squared_error: 0.4707 - accuracy: 0.6636\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.5287 - mean_squared_error: 0.5337 - accuracy: 0.6514\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.4989 - mean_squared_error: 0.4134 - accuracy: 0.6269\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 0.4919 - mean_squared_error: 0.4028 - accuracy: 0.6269\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4980 - mean_squared_error: 0.3862 - accuracy: 0.5963\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.4956 - mean_squared_error: 0.3940 - accuracy: 0.6361\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.4871 - mean_squared_error: 0.4044 - accuracy: 0.6208\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4877 - mean_squared_error: 0.3916 - accuracy: 0.6239\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.4757 - mean_squared_error: 0.3886 - accuracy: 0.6606\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.4637 - mean_squared_error: 0.3299 - accuracy: 0.5933\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.4501 - mean_squared_error: 0.3173 - accuracy: 0.6269\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4917 - mean_squared_error: 0.3721 - accuracy: 0.5810\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.4113 - mean_squared_error: 0.2768 - accuracy: 0.6820\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.4188 - mean_squared_error: 0.2846 - accuracy: 0.6544\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.4356 - mean_squared_error: 0.2885 - accuracy: 0.6269\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.4045 - mean_squared_error: 0.2688 - accuracy: 0.6881\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3970 - mean_squared_error: 0.2604 - accuracy: 0.6820\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3993 - mean_squared_error: 0.2553 - accuracy: 0.6758\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.4005 - mean_squared_error: 0.2471 - accuracy: 0.6789\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.4382 - mean_squared_error: 0.2979 - accuracy: 0.6208\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.4111 - mean_squared_error: 0.2600 - accuracy: 0.6636\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 33us/sample - loss: 0.4118 - mean_squared_error: 0.2614 - accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3980 - mean_squared_error: 0.2414 - accuracy: 0.6636\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4180 - mean_squared_error: 0.2696 - accuracy: 0.6514\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 0.3984 - mean_squared_error: 0.2542 - accuracy: 0.6850\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.3934 - mean_squared_error: 0.2389 - accuracy: 0.6850\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3891 - mean_squared_error: 0.2490 - accuracy: 0.6820\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 34us/sample - loss: 0.3807 - mean_squared_error: 0.2300 - accuracy: 0.6820\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3822 - mean_squared_error: 0.2179 - accuracy: 0.7034\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 33us/sample - loss: 0.3758 - mean_squared_error: 0.2246 - accuracy: 0.7095\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3723 - mean_squared_error: 0.2253 - accuracy: 0.6942\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.3694 - mean_squared_error: 0.2190 - accuracy: 0.7156\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3965 - mean_squared_error: 0.2523 - accuracy: 0.6911\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3712 - mean_squared_error: 0.2285 - accuracy: 0.7125\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.3847 - mean_squared_error: 0.2377 - accuracy: 0.6881\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3663 - mean_squared_error: 0.2193 - accuracy: 0.7125\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3788 - mean_squared_error: 0.2300 - accuracy: 0.6758\n",
      "Epoch 58/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3497 - mean_squared_error: 0.1973 - accuracy: 0.7523\n",
      "Epoch 59/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.3790 - mean_squared_error: 0.2231 - accuracy: 0.7156\n",
      "Epoch 60/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3743 - mean_squared_error: 0.2198 - accuracy: 0.7095\n",
      "Epoch 61/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3494 - mean_squared_error: 0.1957 - accuracy: 0.7309\n",
      "Epoch 62/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.3573 - mean_squared_error: 0.2030 - accuracy: 0.7156\n",
      "Epoch 63/100\n",
      "327/327 [==============================] - 0s 57us/sample - loss: 0.3671 - mean_squared_error: 0.2088 - accuracy: 0.7095\n",
      "Epoch 64/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3622 - mean_squared_error: 0.2147 - accuracy: 0.7034\n",
      "Epoch 65/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3562 - mean_squared_error: 0.2092 - accuracy: 0.7217\n",
      "Epoch 66/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3686 - mean_squared_error: 0.2135 - accuracy: 0.7064\n",
      "Epoch 67/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.3483 - mean_squared_error: 0.1954 - accuracy: 0.7523\n",
      "Epoch 68/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3555 - mean_squared_error: 0.2075 - accuracy: 0.7339\n",
      "Epoch 69/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3612 - mean_squared_error: 0.2091 - accuracy: 0.7248\n",
      "Epoch 70/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.3678 - mean_squared_error: 0.2151 - accuracy: 0.7187\n",
      "Epoch 71/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.3586 - mean_squared_error: 0.2181 - accuracy: 0.7339\n",
      "Epoch 72/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.3520 - mean_squared_error: 0.2196 - accuracy: 0.7278\n",
      "Epoch 73/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.3659 - mean_squared_error: 0.2122 - accuracy: 0.7156\n",
      "Epoch 74/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.3508 - mean_squared_error: 0.1987 - accuracy: 0.7462\n",
      "Epoch 75/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3441 - mean_squared_error: 0.1965 - accuracy: 0.7217\n",
      "Epoch 76/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.3682 - mean_squared_error: 0.2283 - accuracy: 0.6972\n",
      "Epoch 77/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3592 - mean_squared_error: 0.2198 - accuracy: 0.7187\n",
      "Epoch 78/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.3611 - mean_squared_error: 0.2117 - accuracy: 0.7248\n",
      "Epoch 79/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3289 - mean_squared_error: 0.1910 - accuracy: 0.7584\n",
      "Epoch 80/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.3495 - mean_squared_error: 0.2071 - accuracy: 0.7431\n",
      "Epoch 81/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.3592 - mean_squared_error: 0.2071 - accuracy: 0.7156\n",
      "Epoch 82/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.3403 - mean_squared_error: 0.1969 - accuracy: 0.7309\n",
      "Epoch 83/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3463 - mean_squared_error: 0.2013 - accuracy: 0.7370\n",
      "Epoch 84/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.3466 - mean_squared_error: 0.2116 - accuracy: 0.7309\n",
      "Epoch 85/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3309 - mean_squared_error: 0.1982 - accuracy: 0.7492\n",
      "Epoch 86/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3355 - mean_squared_error: 0.1979 - accuracy: 0.7492\n",
      "Epoch 87/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3450 - mean_squared_error: 0.2119 - accuracy: 0.7431\n",
      "Epoch 88/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3482 - mean_squared_error: 0.2099 - accuracy: 0.7278\n",
      "Epoch 89/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.3439 - mean_squared_error: 0.2075 - accuracy: 0.7339\n",
      "164/164 [==============================] - 0s 305us/sample - loss: 0.3332 - mean_squared_error: 0.1885 - accuracy: 0.7378\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   1.7s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 714us/sample - loss: 1.7493 - mean_squared_error: 21.4233 - accuracy: 0.4954\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 1.5993 - mean_squared_error: 9.8525 - accuracy: 0.4954\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 1.3840 - mean_squared_error: 8.0606 - accuracy: 0.5535\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 67us/sample - loss: 1.2701 - mean_squared_error: 6.5250 - accuracy: 0.5382\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 1.2708 - mean_squared_error: 5.0782 - accuracy: 0.5229\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 1.1706 - mean_squared_error: 4.4456 - accuracy: 0.5566\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 1.0485 - mean_squared_error: 3.5844 - accuracy: 0.5596\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 1.1043 - mean_squared_error: 6.2823 - accuracy: 0.5199\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.9690 - mean_squared_error: 2.1577 - accuracy: 0.5596\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.9552 - mean_squared_error: 2.1946 - accuracy: 0.5352\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.8342 - mean_squared_error: 1.3621 - accuracy: 0.5719\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 40us/sample - loss: 0.8010 - mean_squared_error: 1.0721 - accuracy: 0.5566\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.8011 - mean_squared_error: 1.3851 - accuracy: 0.5810\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.7827 - mean_squared_error: 2.3847 - accuracy: 0.5933\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.7996 - mean_squared_error: 2.2868 - accuracy: 0.5657\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 63us/sample - loss: 0.6864 - mean_squared_error: 0.7579 - accuracy: 0.5566\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 32us/sample - loss: 0.6555 - mean_squared_error: 0.8563 - accuracy: 0.5810\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.6382 - mean_squared_error: 0.7129 - accuracy: 0.6024\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.6282 - mean_squared_error: 0.7300 - accuracy: 0.5872\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.5935 - mean_squared_error: 0.5715 - accuracy: 0.5872\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.5862 - mean_squared_error: 0.5877 - accuracy: 0.6086\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.5552 - mean_squared_error: 0.4844 - accuracy: 0.5719\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.5688 - mean_squared_error: 0.5045 - accuracy: 0.5872\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.5456 - mean_squared_error: 0.4833 - accuracy: 0.6024\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.5317 - mean_squared_error: 0.4392 - accuracy: 0.5902\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.5043 - mean_squared_error: 0.3942 - accuracy: 0.6208\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 33us/sample - loss: 0.4798 - mean_squared_error: 0.3744 - accuracy: 0.6361\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.4757 - mean_squared_error: 0.5440 - accuracy: 0.6422\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.4649 - mean_squared_error: 0.4034 - accuracy: 0.6697\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4676 - mean_squared_error: 0.3400 - accuracy: 0.6361\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.4751 - mean_squared_error: 0.4809 - accuracy: 0.6422\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4498 - mean_squared_error: 0.3205 - accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.4449 - mean_squared_error: 0.3113 - accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.4297 - mean_squared_error: 0.3140 - accuracy: 0.7064\n",
      "Epoch 35/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.4298 - mean_squared_error: 0.2962 - accuracy: 0.6911\n",
      "Epoch 36/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.4326 - mean_squared_error: 0.3016 - accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.4330 - mean_squared_error: 0.2845 - accuracy: 0.6697\n",
      "Epoch 38/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.4174 - mean_squared_error: 0.3309 - accuracy: 0.6575\n",
      "Epoch 39/100\n",
      "327/327 [==============================] - 0s 32us/sample - loss: 0.4187 - mean_squared_error: 0.2607 - accuracy: 0.6911\n",
      "Epoch 40/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.4333 - mean_squared_error: 0.2886 - accuracy: 0.6575\n",
      "Epoch 41/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3889 - mean_squared_error: 0.2676 - accuracy: 0.7370\n",
      "Epoch 42/100\n",
      "327/327 [==============================] - 0s 34us/sample - loss: 0.4101 - mean_squared_error: 0.2692 - accuracy: 0.6728\n",
      "Epoch 43/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.4361 - mean_squared_error: 0.2914 - accuracy: 0.6361\n",
      "Epoch 44/100\n",
      "327/327 [==============================] - 0s 61us/sample - loss: 0.4065 - mean_squared_error: 0.2607 - accuracy: 0.7156\n",
      "Epoch 45/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.3877 - mean_squared_error: 0.2452 - accuracy: 0.6942\n",
      "Epoch 46/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.4065 - mean_squared_error: 0.2649 - accuracy: 0.6636\n",
      "Epoch 47/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3681 - mean_squared_error: 0.2165 - accuracy: 0.7125\n",
      "Epoch 48/100\n",
      "327/327 [==============================] - 0s 31us/sample - loss: 0.3823 - mean_squared_error: 0.2369 - accuracy: 0.7064\n",
      "Epoch 49/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: 0.4059 - mean_squared_error: 0.2426 - accuracy: 0.6881\n",
      "Epoch 50/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: 0.3983 - mean_squared_error: 0.2598 - accuracy: 0.7003\n",
      "Epoch 51/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 0.3701 - mean_squared_error: 0.2264 - accuracy: 0.7278\n",
      "Epoch 52/100\n",
      "327/327 [==============================] - ETA: 0s - loss: 0.3788 - mean_squared_error: 0.2469 - accuracy: 0.687 - 0s 42us/sample - loss: 0.3694 - mean_squared_error: 0.2198 - accuracy: 0.7156\n",
      "Epoch 53/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3808 - mean_squared_error: 0.2324 - accuracy: 0.7003\n",
      "Epoch 54/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 0.3795 - mean_squared_error: 0.2208 - accuracy: 0.6820\n",
      "Epoch 55/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3705 - mean_squared_error: 0.2186 - accuracy: 0.7187\n",
      "Epoch 56/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3841 - mean_squared_error: 0.2217 - accuracy: 0.6820\n",
      "Epoch 57/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 0.3773 - mean_squared_error: 0.2265 - accuracy: 0.7217\n",
      "164/164 [==============================] - 0s 319us/sample - loss: 0.3666 - mean_squared_error: 0.1987 - accuracy: 0.7378\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   1.2s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 698us/sample - loss: 3.5783 - mean_squared_error: 1561.6104 - accuracy: 0.5488\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 1.3096 - mean_squared_error: 11.9039 - accuracy: 0.5305\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 34us/sample - loss: 1.1956 - mean_squared_error: 6.8261 - accuracy: 0.5732\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 1.3250 - mean_squared_error: 15.5223 - accuracy: 0.5671\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 1.2644 - mean_squared_error: 10.0874 - accuracy: 0.5244\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328/328 [==============================] - 0s 46us/sample - loss: 2.4635 - mean_squared_error: 751.6387 - accuracy: 0.5701\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 2.3312 - mean_squared_error: 588.1015 - accuracy: 0.5488\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.9569 - mean_squared_error: 2.7788 - accuracy: 0.5396\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 2.0324 - mean_squared_error: 444.0839 - accuracy: 0.5579\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.8408 - mean_squared_error: 2.2489 - accuracy: 0.6037\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 57us/sample - loss: 2.0827 - mean_squared_error: 460.3748 - accuracy: 0.5396\n",
      "Epoch 12/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 1.6960 - mean_squared_error: 240.3209 - accuracy: 0.5823\n",
      "Epoch 13/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 1.5438 - mean_squared_error: 206.6782 - accuracy: 0.6372\n",
      "Epoch 14/100\n",
      "328/328 [==============================] - 0s 33us/sample - loss: 0.9693 - mean_squared_error: 13.2824 - accuracy: 0.5854\n",
      "Epoch 15/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 1.4071 - mean_squared_error: 153.3282 - accuracy: 0.5488\n",
      "Epoch 16/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.9615 - mean_squared_error: 19.6427 - accuracy: 0.5427\n",
      "Epoch 17/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 1.4701 - mean_squared_error: 193.9512 - accuracy: 0.5945\n",
      "Epoch 18/100\n",
      "328/328 [==============================] - 0s 35us/sample - loss: 1.2172 - mean_squared_error: 99.1677 - accuracy: 0.6006\n",
      "Epoch 19/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 1.3607 - mean_squared_error: 131.7974 - accuracy: 0.5457\n",
      "Epoch 20/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.6171 - mean_squared_error: 0.7613 - accuracy: 0.6037\n",
      "Epoch 21/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.8065 - mean_squared_error: 11.0450 - accuracy: 0.5610\n",
      "Epoch 22/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 1.0370 - mean_squared_error: 60.4459 - accuracy: 0.5976\n",
      "Epoch 23/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.9873 - mean_squared_error: 49.7921 - accuracy: 0.6128\n",
      "Epoch 24/100\n",
      "328/328 [==============================] - 0s 36us/sample - loss: 0.9126 - mean_squared_error: 37.5144 - accuracy: 0.5915\n",
      "Epoch 25/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.8637 - mean_squared_error: 16.2936 - accuracy: 0.5366\n",
      "Epoch 26/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.8365 - mean_squared_error: 27.5618 - accuracy: 0.6707\n",
      "Epoch 27/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.5736 - mean_squared_error: 0.6898 - accuracy: 0.6280\n",
      "Epoch 28/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.9765 - mean_squared_error: 55.5804 - accuracy: 0.6220\n",
      "Epoch 29/100\n",
      "328/328 [==============================] - 0s 50us/sample - loss: 0.7956 - mean_squared_error: 18.3764 - accuracy: 0.6128\n",
      "Epoch 30/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.8496 - mean_squared_error: 38.0171 - accuracy: 0.6372\n",
      "Epoch 31/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 0.7396 - mean_squared_error: 8.7809 - accuracy: 0.5854\n",
      "Epoch 32/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.6450 - mean_squared_error: 4.7492 - accuracy: 0.6280\n",
      "Epoch 33/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.5928 - mean_squared_error: 2.6919 - accuracy: 0.6311\n",
      "Epoch 34/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.5799 - mean_squared_error: 0.9596 - accuracy: 0.5915\n",
      "Epoch 35/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.5454 - mean_squared_error: 1.8593 - accuracy: 0.5915\n",
      "Epoch 36/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.5348 - mean_squared_error: 0.6016 - accuracy: 0.6067\n",
      "Epoch 37/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.5082 - mean_squared_error: 0.5219 - accuracy: 0.6402\n",
      "Epoch 38/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.4933 - mean_squared_error: 0.4997 - accuracy: 0.6555\n",
      "Epoch 39/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.5062 - mean_squared_error: 0.6807 - accuracy: 0.6311\n",
      "Epoch 40/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.5151 - mean_squared_error: 0.6713 - accuracy: 0.6585\n",
      "Epoch 41/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.6775 - mean_squared_error: 11.9647 - accuracy: 0.6494\n",
      "Epoch 42/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.7163 - mean_squared_error: 17.7533 - accuracy: 0.6037\n",
      "Epoch 43/100\n",
      "328/328 [==============================] - 0s 52us/sample - loss: 0.4683 - mean_squared_error: 0.3856 - accuracy: 0.6189\n",
      "Epoch 44/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.6736 - mean_squared_error: 10.2718 - accuracy: 0.5976\n",
      "Epoch 45/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 0.4899 - mean_squared_error: 0.6731 - accuracy: 0.6433\n",
      "Epoch 46/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.4916 - mean_squared_error: 0.5114 - accuracy: 0.6250\n",
      "Epoch 47/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.6586 - mean_squared_error: 11.9743 - accuracy: 0.6524\n",
      "Epoch 48/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.6018 - mean_squared_error: 11.2846 - accuracy: 0.6768\n",
      "Epoch 49/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.4566 - mean_squared_error: 0.3848 - accuracy: 0.6799\n",
      "Epoch 50/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.6094 - mean_squared_error: 6.8884 - accuracy: 0.6341\n",
      "Epoch 51/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: 0.4626 - mean_squared_error: 0.4584 - accuracy: 0.6646\n",
      "Epoch 52/100\n",
      "328/328 [==============================] - 0s 36us/sample - loss: 0.4531 - mean_squared_error: 0.3489 - accuracy: 0.6402\n",
      "Epoch 53/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.4443 - mean_squared_error: 0.3315 - accuracy: 0.6280\n",
      "Epoch 54/100\n",
      "328/328 [==============================] - 0s 36us/sample - loss: 0.4197 - mean_squared_error: 0.3063 - accuracy: 0.6829\n",
      "Epoch 55/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.4042 - mean_squared_error: 0.3627 - accuracy: 0.7134\n",
      "Epoch 56/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.5590 - mean_squared_error: 5.8209 - accuracy: 0.6707\n",
      "Epoch 57/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.5632 - mean_squared_error: 5.6697 - accuracy: 0.6372\n",
      "Epoch 58/100\n",
      "328/328 [==============================] - 0s 33us/sample - loss: 0.5326 - mean_squared_error: 6.0603 - accuracy: 0.6860\n",
      "Epoch 59/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4324 - mean_squared_error: 0.3139 - accuracy: 0.6616\n",
      "Epoch 60/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.4282 - mean_squared_error: 0.3335 - accuracy: 0.6616\n",
      "Epoch 61/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4341 - mean_squared_error: 0.3028 - accuracy: 0.6189\n",
      "Epoch 62/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.5075 - mean_squared_error: 4.2472 - accuracy: 0.6890\n",
      "Epoch 63/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.4989 - mean_squared_error: 3.3873 - accuracy: 0.6768\n",
      "Epoch 64/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.4388 - mean_squared_error: 0.3924 - accuracy: 0.6555\n",
      "Epoch 65/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.4032 - mean_squared_error: 0.2765 - accuracy: 0.6982\n",
      "Epoch 66/100\n",
      "328/328 [==============================] - 0s 86us/sample - loss: 0.5190 - mean_squared_error: 4.3053 - accuracy: 0.6738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4947 - mean_squared_error: 3.5031 - accuracy: 0.7043\n",
      "Epoch 68/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.5017 - mean_squared_error: 3.3910 - accuracy: 0.6677\n",
      "Epoch 69/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.4874 - mean_squared_error: 2.9363 - accuracy: 0.6860\n",
      "Epoch 70/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.4601 - mean_squared_error: 1.6637 - accuracy: 0.7165\n",
      "Epoch 71/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: 0.4014 - mean_squared_error: 0.2593 - accuracy: 0.6921\n",
      "Epoch 72/100\n",
      "328/328 [==============================] - 0s 66us/sample - loss: 0.3766 - mean_squared_error: 0.2259 - accuracy: 0.7043\n",
      "Epoch 73/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.4512 - mean_squared_error: 2.2823 - accuracy: 0.7317\n",
      "Epoch 74/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3985 - mean_squared_error: 0.2668 - accuracy: 0.6860\n",
      "Epoch 75/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.4118 - mean_squared_error: 0.2790 - accuracy: 0.6463\n",
      "Epoch 76/100\n",
      "328/328 [==============================] - 0s 35us/sample - loss: 0.3690 - mean_squared_error: 0.2310 - accuracy: 0.7195\n",
      "Epoch 77/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.3865 - mean_squared_error: 0.2523 - accuracy: 0.7104\n",
      "Epoch 78/100\n",
      "328/328 [==============================] - 0s 34us/sample - loss: 0.4338 - mean_squared_error: 1.2733 - accuracy: 0.7287\n",
      "Epoch 79/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.3765 - mean_squared_error: 0.2329 - accuracy: 0.6982\n",
      "Epoch 80/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3840 - mean_squared_error: 0.2451 - accuracy: 0.7043\n",
      "Epoch 81/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.4639 - mean_squared_error: 1.5904 - accuracy: 0.7012\n",
      "Epoch 82/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 0.3760 - mean_squared_error: 0.2347 - accuracy: 0.7256\n",
      "Epoch 83/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.3703 - mean_squared_error: 0.2385 - accuracy: 0.7287\n",
      "Epoch 84/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.4074 - mean_squared_error: 1.0202 - accuracy: 0.7378\n",
      "Epoch 85/100\n",
      "328/328 [==============================] - 0s 35us/sample - loss: 0.4289 - mean_squared_error: 1.2640 - accuracy: 0.7073\n",
      "Epoch 86/100\n",
      "328/328 [==============================] - 0s 36us/sample - loss: 0.3655 - mean_squared_error: 0.2326 - accuracy: 0.7348\n",
      "Epoch 87/100\n",
      "328/328 [==============================] - 0s 59us/sample - loss: 0.3854 - mean_squared_error: 0.2462 - accuracy: 0.7012\n",
      "Epoch 88/100\n",
      "328/328 [==============================] - 0s 41us/sample - loss: 0.4134 - mean_squared_error: 0.6921 - accuracy: 0.7012\n",
      "Epoch 89/100\n",
      "328/328 [==============================] - 0s 33us/sample - loss: 0.4129 - mean_squared_error: 0.9523 - accuracy: 0.7012\n",
      "Epoch 90/100\n",
      "328/328 [==============================] - 0s 45us/sample - loss: 0.3475 - mean_squared_error: 0.2160 - accuracy: 0.7287\n",
      "Epoch 91/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.3617 - mean_squared_error: 0.2270 - accuracy: 0.7287\n",
      "Epoch 92/100\n",
      "328/328 [==============================] - 0s 54us/sample - loss: 0.3545 - mean_squared_error: 0.2305 - accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "328/328 [==============================] - 0s 56us/sample - loss: 0.4037 - mean_squared_error: 0.6904 - accuracy: 0.7073\n",
      "Epoch 94/100\n",
      "328/328 [==============================] - 0s 32us/sample - loss: 0.3826 - mean_squared_error: 0.2642 - accuracy: 0.7195\n",
      "Epoch 95/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.3807 - mean_squared_error: 0.7512 - accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: 0.3649 - mean_squared_error: 0.2250 - accuracy: 0.7256\n",
      "Epoch 97/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 0.3688 - mean_squared_error: 0.2311 - accuracy: 0.7226\n",
      "Epoch 98/100\n",
      "328/328 [==============================] - 0s 51us/sample - loss: 0.3677 - mean_squared_error: 0.2352 - accuracy: 0.7256\n",
      "Epoch 99/100\n",
      "328/328 [==============================] - 0s 38us/sample - loss: 0.3416 - mean_squared_error: 0.2120 - accuracy: 0.7256\n",
      "Epoch 100/100\n",
      "328/328 [==============================] - 0s 37us/sample - loss: 0.4002 - mean_squared_error: 0.6209 - accuracy: 0.7073\n",
      "163/163 [==============================] - 0s 352us/sample - loss: 0.3592 - mean_squared_error: 0.4269 - accuracy: 0.7546\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function linear at 0x7f4eed7e5ea0>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.07123791509709439, loss_fn=mae, n_hidden=1, n_neurons=9, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   1.9s\n",
      "[CV] activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 80us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "164/164 [==============================] - 0s 386us/sample - loss: 0.3232 - mean_squared_error: 0.3232 - accuracy: 0.6768\n",
      "[CV]  activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 56us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "164/164 [==============================] - 0s 372us/sample - loss: 0.2866 - mean_squared_error: 0.2866 - accuracy: 0.7134\n",
      "[CV]  activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 1ms/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 60us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 61us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 50us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "163/163 [==============================] - 0s 386us/sample - loss: 0.3006 - mean_squared_error: 0.3006 - accuracy: 0.6994\n",
      "[CV]  activation=<function relu at 0x7f4eed7e5bf8>, drop_out_rate=0.1, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0005152852103689999, loss_fn=mae, n_hidden=3, n_neurons=8, optimizer=<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>, total=   0.7s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 1ms/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 59us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 46us/sample - loss: 0.2936 - mean_squared_error: 0.2936 - accuracy: 0.7064\n",
      "164/164 [==============================] - 0s 326us/sample - loss: 0.3232 - mean_squared_error: 0.3232 - accuracy: 0.6768\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   0.7s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 699us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 36us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 53us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.3119 - mean_squared_error: 0.3119 - accuracy: 0.6881\n",
      "164/164 [==============================] - 0s 321us/sample - loss: 0.2866 - mean_squared_error: 0.2866 - accuracy: 0.7134\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   0.5s\n",
      "[CV] activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 696us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 49us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 40us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 46us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 55us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 39us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "Epoch 11/100\n",
      "328/328 [==============================] - 0s 53us/sample - loss: 0.3049 - mean_squared_error: 0.3049 - accuracy: 0.6951\n",
      "163/163 [==============================] - 0s 333us/sample - loss: 0.3006 - mean_squared_error: 0.3006 - accuracy: 0.6994\n",
      "[CV]  activation=<function hard_sigmoid at 0x7f4eed7e5e18>, drop_out_rate=0.0, exit_layer_act=<function softmax at 0x7f4eed7e5950>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.0003454375917664631, loss_fn=mae, n_hidden=1, n_neurons=134, optimizer=<tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>, total=   0.5s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n",
      "327/327 [==============================] - 0s 690us/sample - loss: 15.2921 - mean_squared_error: 9005.9004 - accuracy: 0.4557\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 35us/sample - loss: 289.2805 - mean_squared_error: 26355038.0000 - accuracy: 0.3578\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3211 \n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 35us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 52us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 54us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 60us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.2936\n",
      "164/164 [==============================] - 0s 325us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3232\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   0.5s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 327 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 695us/sample - loss: 0.9458 - mean_squared_error: 3.8716 - accuracy: 0.2936\n",
      "Epoch 2/100\n",
      "327/327 [==============================] - 0s 35us/sample - loss: 1367.1187 - mean_squared_error: 610495872.0000 - accuracy: 0.3211\n",
      "Epoch 3/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 637478.7425 - mean_squared_error: 132885700935680.0000 - accuracy: 0.3058\n",
      "Epoch 4/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 1.9156 - mean_squared_error: 482.8112 - accuracy: 0.2966\n",
      "Epoch 5/100\n",
      "327/327 [==============================] - 0s 34us/sample - loss: 0.7132 - mean_squared_error: 1.0293 - accuracy: 0.3242\n",
      "Epoch 6/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.7045 - mean_squared_error: 1.1265 - accuracy: 0.3180\n",
      "Epoch 7/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 746.8597 - mean_squared_error: 182038320.0000 - accuracy: 0.2997\n",
      "Epoch 8/100\n",
      "327/327 [==============================] - 0s 32us/sample - loss: 0.9803 - mean_squared_error: 28.2516 - accuracy: 0.3119\n",
      "Epoch 9/100\n",
      "327/327 [==============================] - 0s 41us/sample - loss: 740.3518 - mean_squared_error: 178568048.0000 - accuracy: 0.2997\n",
      "Epoch 10/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.6772 - mean_squared_error: 0.6402 - accuracy: 0.3150\n",
      "Epoch 11/100\n",
      "327/327 [==============================] - 0s 30us/sample - loss: 0.6804 - mean_squared_error: 0.6396 - accuracy: 0.3119\n",
      "Epoch 12/100\n",
      "327/327 [==============================] - 0s 37us/sample - loss: 378.8390 - mean_squared_error: 46751468.0000 - accuracy: 0.3058\n",
      "Epoch 13/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 0.6981 - mean_squared_error: 0.6697 - accuracy: 0.2936\n",
      "Epoch 14/100\n",
      "327/327 [==============================] - 0s 34us/sample - loss: 0.6955 - mean_squared_error: 0.7176 - accuracy: 0.3028\n",
      "Epoch 15/100\n",
      "327/327 [==============================] - 0s 51us/sample - loss: 0.6837 - mean_squared_error: 0.6438 - accuracy: 0.3119\n",
      "Epoch 16/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 0.6932 - mean_squared_error: 0.6734 - accuracy: 0.2997\n",
      "Epoch 17/100\n",
      "327/327 [==============================] - 0s 43us/sample - loss: 0.6745 - mean_squared_error: 0.6423 - accuracy: 0.3211\n",
      "Epoch 18/100\n",
      "327/327 [==============================] - 0s 40us/sample - loss: 0.6960 - mean_squared_error: 0.6894 - accuracy: 0.3089\n",
      "Epoch 19/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.8055 - mean_squared_error: 4.5545 - accuracy: 0.3058\n",
      "Epoch 20/100\n",
      "327/327 [==============================] - 0s 49us/sample - loss: 0.6791 - mean_squared_error: 0.6446 - accuracy: 0.3150\n",
      "Epoch 21/100\n",
      "327/327 [==============================] - 0s 45us/sample - loss: 0.7043 - mean_squared_error: 0.8862 - accuracy: 0.3242\n",
      "Epoch 22/100\n",
      "327/327 [==============================] - 0s 58us/sample - loss: 0.7129 - mean_squared_error: 0.9145 - accuracy: 0.3180\n",
      "Epoch 23/100\n",
      "327/327 [==============================] - 0s 50us/sample - loss: 0.6730 - mean_squared_error: 0.6489 - accuracy: 0.3211\n",
      "Epoch 24/100\n",
      "327/327 [==============================] - 0s 38us/sample - loss: 0.6775 - mean_squared_error: 0.6442 - accuracy: 0.3150\n",
      "Epoch 25/100\n",
      "327/327 [==============================] - 0s 42us/sample - loss: 39.0777 - mean_squared_error: 481294.0000 - accuracy: 0.3150\n",
      "Epoch 26/100\n",
      "327/327 [==============================] - 0s 66us/sample - loss: 0.7017 - mean_squared_error: 0.7574 - accuracy: 0.3089\n",
      "Epoch 27/100\n",
      "327/327 [==============================] - 0s 34us/sample - loss: 0.6784 - mean_squared_error: 0.6514 - accuracy: 0.3150\n",
      "Epoch 28/100\n",
      "327/327 [==============================] - 0s 47us/sample - loss: 11.8853 - mean_squared_error: 41002.8984 - accuracy: 0.3119\n",
      "Epoch 29/100\n",
      "327/327 [==============================] - 0s 39us/sample - loss: 0.6801 - mean_squared_error: 0.6622 - accuracy: 0.3180\n",
      "Epoch 30/100\n",
      "327/327 [==============================] - 0s 48us/sample - loss: 0.6752 - mean_squared_error: 0.6479 - accuracy: 0.3119\n",
      "Epoch 31/100\n",
      "327/327 [==============================] - 0s 55us/sample - loss: 8.4128 - mean_squared_error: 19614.6387 - accuracy: 0.3211\n",
      "Epoch 32/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.6760 - mean_squared_error: 0.6531 - accuracy: 0.3150\n",
      "Epoch 33/100\n",
      "327/327 [==============================] - 0s 44us/sample - loss: 0.7438 - mean_squared_error: 2.5913 - accuracy: 0.3303\n",
      "164/164 [==============================] - 0s 323us/sample - loss: 0.7052 - mean_squared_error: 0.6866 - accuracy: 0.2866\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   0.8s\n",
      "[CV] activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18> \n",
      "Train on 328 samples\n",
      "Epoch 1/100\n",
      "328/328 [==============================] - 0s 707us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3659                              \n",
      "Epoch 2/100\n",
      "328/328 [==============================] - 0s 58us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 3/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 4/100\n",
      "328/328 [==============================] - 0s 42us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 5/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 6/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 7/100\n",
      "328/328 [==============================] - 0s 48us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 8/100\n",
      "328/328 [==============================] - 0s 44us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 9/100\n",
      "328/328 [==============================] - 0s 43us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "Epoch 10/100\n",
      "328/328 [==============================] - 0s 47us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3049\n",
      "163/163 [==============================] - 0s 306us/sample - loss: nan - mean_squared_error: nan - accuracy: 0.3006\n",
      "[CV]  activation=<function exponential at 0x7f4eed7e5d90>, drop_out_rate=0.30000000000000004, exit_layer_act=<function exponential at 0x7f4eed7e5d90>, input_shape=[ 1.37463856 -0.52812706 -0.22118982  0.28761093  0.53732105  0.\n",
      "  1.          0.          1.          1.          0.          0.\n",
      "  0.          1.          0.          1.          0.          0.\n",
      "  0.          1.        ], learning_rate=0.00012373913042111907, loss_fn=mae, n_hidden=1, n_neurons=44, optimizer=<tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x7f4eec396c18>, total=   0.5s\n",
      "Train on 491 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491/491 [==============================] - 0s 647us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 2/100\n",
      "491/491 [==============================] - 0s 41us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 3/100\n",
      "491/491 [==============================] - 0s 45us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 4/100\n",
      "491/491 [==============================] - 0s 48us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 5/100\n",
      "491/491 [==============================] - 0s 41us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 6/100\n",
      "491/491 [==============================] - 0s 45us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 7/100\n",
      "491/491 [==============================] - 0s 42us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 8/100\n",
      "491/491 [==============================] - 0s 39us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 9/100\n",
      "491/491 [==============================] - 0s 45us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 10/100\n",
      "491/491 [==============================] - 0s 41us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 11/100\n",
      "491/491 [==============================] - 0s 57us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n",
      "Epoch 12/100\n",
      "491/491 [==============================] - 0s 46us/sample - loss: 0.3035 - mean_squared_error: 0.3035 - accuracy: 0.6965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7f4eec396eb8>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'activation': [<function elu at 0x7f4eed7e59d8>,\n",
       "                                                       <function exponential at 0x7f4eed7e5d90>,\n",
       "                                                       <function hard_sigmoid at 0x7f4eed7e5e18>,\n",
       "                                                       <function linear at 0x7f4ee...\n",
       "                                                      <tensorflow.python.keras.optimizer_v2.ftrl.Ftrl object at 0x7f4eec396828>,\n",
       "                                                      <tensorflow.python.keras.optimizer_v2.adadelta.Adadelta object at 0x7f4eec3969b0>,\n",
       "                                                      <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f4eec396940>,\n",
       "                                                      <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f4eec396978>]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.fit(x_train, y_train, epochs=100, \n",
    "#                    validation_data=(x_valid, y_valid), \n",
    "                   callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 599us/sample - loss: 0.3496 - mean_squared_error: 0.3496 - accuracy: 0.6504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3495934946023352"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search_cv.best_estimator_.score(x_valid, y_valid) #average 77 w/out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairly small dataset, w/ only aprox 600 observations, best model was the SVC achieving consistently 80%. However, the model could be overfitting. More data is likely needed, as well as getting the loan_status on the test set, to evaluate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
